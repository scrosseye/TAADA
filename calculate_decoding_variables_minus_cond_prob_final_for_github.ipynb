{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1f57fa4-2d10-4620-a3da-0bc38b51ac45",
   "metadata": {},
   "source": [
    "# Decoding Tool\n",
    "\n",
    "This script will calculate a number of features for specific words related to decoding, many of which come from the CMU pronunciation dictionary.\n",
    "\n",
    "It will be used to develop a dataframe that contains observations that are English words and variables that are counts related to decoding for each word.\n",
    "\n",
    "It will calculate the following\n",
    "\n",
    "1. Syllables per word\n",
    "2. Number of letters per word\n",
    "3. Number of phonemes: Differences between the number of characters in a word and the number of phonemes in that word\n",
    "4. Discrepancy (raw and mean)\n",
    "5. Average syllable length\n",
    "6. Blends (consonants, vowels, and both): Average character per phoneme\n",
    "7. Grapheme‑Phoneme Complexity (Berndt et al. (1987) calculated in two ways\n",
    "\n",
    "    7a. The mid, max, prior, average of Grapheme‑Phoneme Complexity by word\n",
    "\n",
    "    7b. The phonological matching of Grapheme‑Phoneme Complexity by word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80245431-9473-423a-a3ae-1960308b114d",
   "metadata": {},
   "source": [
    "We will start with calculating variables using the CMU pronunciation dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6d9d17-ead2-4268-99a7-96ebda079d66",
   "metadata": {},
   "source": [
    "First, where are we?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed01e5c5-d5e6-4059-9a9c-7d14216ba364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['everything_except_vowel_prob.csv', 'calculate_decoding_measures_from_texts_spacy.ipynb', 'CLEAR_corpus_prac.csv', 'problems_w_vowel_list_lengths.csv', 'CLEAR_corpus_final.csv', 'Screenshot 2023-06-02 at 1.10.55 PM.png', 'consonant_cond_prob_berndt_no_except.csv', '.DS_Store', 'vow_cond_prob_berndt_no_except_one_char.csv', 'joon_cond_prob', 'decoding_measure_notes.rtf', 'cons_cond_prob_berndt_no_except_one_char.csv', 'dic_prac.ipynb', 'cons_cond_prob_berndt_no_except_two_char.csv', 'corr_matrix_decoding_variables_clear.csv', 'decoding_1.0_for_Joon.zip', 'vow_cond_prob_berndt_no_except_two_char.csv', 'berndt_data_with_cmu_phones.xlsx', 'vowel_cond_prob_berndt.csv', 'decoder_dataframe_analytics', 'vow_cond_prob_berndt_no_except_three_char.csv', 'cmu_phones_vowels.csv', 'berndt_notes.rtf', 'prac_words_berndt.csv', 'python-regular-expressions-cheat-sheet.pdf', 'decoding_2.ipynb', 'decoding_1_dataframe.csv', 'consonant_cond_prob_berndt.csv', 'All_variables_in_decoder_project.xlsx', 'berndt deletions and re rules.rtf', 'correlations_clear_decoding.Rmd', 'Saha-Cutting-Del Tufo-Bailey-DSyM-2020.pdf', 'everything_including_vowel_prob.csv', 'Screenshot 2023-06-02 at 1.11.05 PM.png', 'decoding_features_clear.csv', 'decoding_4.ipynb', 'vow_cond_prob_berndt_except_two_char.csv', 'cons_cond_prob_berndt_no_except_three_char.csv', 'decoding_6.ipynb', 'Empirically derived probabilities for grapheme to phoneme correspondences in English copy.pdf', 'berndt_data_all.xlsx', '.ipynb_checkpoints', 'decoding_1.ipynb', 'berndt_data.xlsx', 'consonant_cond_prob_berndt_except.csv', 'interpret_decoder_variables_reference_clear_corpus.xlsx', 'CLEAR_corpus_prac_simple.csv', 'correlations_interpret_decoding.xlsx', 'decoding_3.ipynb', 'vow_cond_prob_berndt_except_one_char.csv', 'processed_condprobs_v4_final.csv', 'Empirically derived probabilities for grapheme to phoneme correspondences in English.pdf', 'cons_cond_prob_berndt_no_except_four_char.csv', 'vow_cond_prob_berndt_no_except_four_char.csv', 'decoding_datasets_cutting_lab', 'cmu_rhyme_dic.csv', 'decoding_5.ipynb']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "390fb960-2749-45d2-b5d5-796420313377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# safe divide function to stop zero counts from causing problems\n",
    "def safe_divide(a, b):\n",
    "    if b != 0:\n",
    "        return a/b\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401246ab-5362-488a-855c-c9a2ebfa655e",
   "metadata": {},
   "source": [
    "## Call in CMU pronunciation dictionary and wrangle data into a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "230bd234-9439-494b-8af0-9e4c5e3fcdcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5p/zd2tqnh90kg4fnzxtpkpx2yh0000gn/T/ipykernel_47471/1224201927.py:9: DtypeWarning: Columns (16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pronounce_df = pd.read_csv('cmu_rhyme_dic.csv', na_values='', header=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0    1    2    3  4    5    6    7    8  9   ... 23 24 25 26 27 28 29  \\\n",
      "0       A  AH0                                      ...                        \n",
      "1    A(1)  EY1                                      ...                        \n",
      "2     A'S  EY1    Z                                 ...                        \n",
      "3      A.  EY1                                      ...                        \n",
      "4    A.'S  EY1    Z                                 ...                        \n",
      "5     A.S  EY1    Z                                 ...                        \n",
      "6  A42128  EY1    F  AO1  R    T  UW1    W  AH1  N  ...                        \n",
      "7      AA  EY2  EY1                                 ...                        \n",
      "8     AAA    T    R  IH2  P  AH0    L  EY1          ...                        \n",
      "9  AABERG  AA1    B  ER0  G                         ...                        \n",
      "\n",
      "  30 31 32  \n",
      "0           \n",
      "1           \n",
      "2           \n",
      "3           \n",
      "4           \n",
      "5           \n",
      "6           \n",
      "7           \n",
      "8           \n",
      "9           \n",
      "\n",
      "[10 rows x 33 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(133779, 33)\n"
     ]
    }
   ],
   "source": [
    "#call in dictionary\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#start with small dataframe\n",
    "#rhyme_df = pd.read_csv('cmu_rhyme_dic_small.csv', na_values='', header=None)\n",
    "\n",
    "#call in dataframe by number of words\n",
    "pronounce_df = pd.read_csv('cmu_rhyme_dic.csv', na_values='', header=None)\n",
    "\n",
    "\n",
    "pronounce_df = pronounce_df.fillna(\"\") #replace nan with nothing\n",
    "result_df = pronounce_df.head(10) #small dataset to view\n",
    "print(result_df)\n",
    "print(type(pronounce_df))\n",
    "print(pronounce_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74e88e7-fe2f-49ad-87c7-f975f94a6d8f",
   "metadata": {},
   "source": [
    "Need to remove all words/observations that have the following characters\n",
    "\n",
    "( or ) these are alternative pronunciations.\n",
    "\n",
    "Clean the words of these\n",
    "\n",
    ".' this get in the way of character counts\n",
    "\n",
    "**but you will also need to remove these from the corpus you are analyzing so a word like parent's become parents (or wouldn't because wouldnt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ce6191e-2be1-4217-bede-16a3dbcc46bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125000, 33)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5p/zd2tqnh90kg4fnzxtpkpx2yh0000gn/T/ipykernel_47471/2200391607.py:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  pronounce_df2[0] = pronounce_df2[0].str.replace(r'\\.', '') #replace . with nothing\n",
      "/var/folders/5p/zd2tqnh90kg4fnzxtpkpx2yh0000gn/T/ipykernel_47471/2200391607.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pronounce_df2[0] = pronounce_df2[0].str.replace(r'\\.', '') #replace . with nothing\n",
      "/var/folders/5p/zd2tqnh90kg4fnzxtpkpx2yh0000gn/T/ipykernel_47471/2200391607.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  pronounce_df2[0] = pronounce_df2[0].str.replace(r'\\'', '') #replace ' with nothing\n",
      "/var/folders/5p/zd2tqnh90kg4fnzxtpkpx2yh0000gn/T/ipykernel_47471/2200391607.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pronounce_df2[0] = pronounce_df2[0].str.replace(r'\\'', '') #replace ' with nothing\n"
     ]
    }
   ],
   "source": [
    "# Remove rows with .\n",
    "\n",
    "pronounce_df2 = pronounce_df[pronounce_df[0].str.contains(\"\\(\") == False] #remove any observations that contain (\n",
    "\n",
    "# Remove . and ' from words\n",
    "\n",
    "pronounce_df2[0] = pronounce_df2[0].str.replace(r'\\.', '') #replace . with nothing\n",
    "pronounce_df2[0] = pronounce_df2[0].str.replace(r'\\'', '') #replace ' with nothing\n",
    "\n",
    "pronounce_df2\n",
    "print(pronounce_df2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bd36bb-6cc9-4e3f-9c22-25f3c4fc4681",
   "metadata": {},
   "source": [
    "**Remove redundant words\n",
    "\n",
    "There are a bunch of words that have multiple pronunciations. We will remove all but the primary pronunciation.\n",
    "\n",
    "Removes around 1,500 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18bc7f78-a5e7-4eb4-9d75-d5bd44707aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(121753, 33)\n"
     ]
    }
   ],
   "source": [
    "#remove rows based on first column but keep first instance of duplicate\n",
    "pronounce_df3 = pronounce_df2.drop_duplicates(subset=[0], keep= 'first')\n",
    "\n",
    "pronounce_df3\n",
    "print(pronounce_df3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97318774-c85d-4d9a-966d-c43793b805e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "['AH0', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "AS\n",
      "['EY1', 'Z', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "A42128\n",
      "['EY1', 'F', 'AO1', 'R', 'T', 'UW1', 'W', 'AH1', 'N', 'T', 'UW1', 'EY1', 'T', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "AA\n",
      "['EY2', 'EY1', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "AAA\n",
      "['T', 'R', 'IH2', 'P', 'AH0', 'L', 'EY1', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n"
     ]
    }
   ],
   "source": [
    "#Convert to dictionary\n",
    "\n",
    "pronounce_df_tran = pronounce_df3.set_index(0).transpose() #this transposes, but also makes column 0 (the words) the header\n",
    "\n",
    "#print(pronounce_df_tran)\n",
    "\n",
    "pronounce_dic_tran =pronounce_df_tran.to_dict('list') #makes it into a single dictionary and uses header as key and list as values\n",
    "\n",
    "#print out key and values\n",
    "\n",
    "\n",
    "#see what is in there\n",
    "counter = 0\n",
    "\n",
    "for key, val in pronounce_dic_tran.items():\n",
    "    print(key)\n",
    "    print(val)\n",
    "    counter += 1\n",
    "    if counter == 5:\n",
    "        break\n",
    "\n",
    "#lots of empty values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e2f6a80-13c5-43f5-94b7-04604d4d2702",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove all empty items from dictionary\n",
    "for key, val in pronounce_dic_tran.items():\n",
    "  while(\"\" in val):\n",
    "    val.remove(\"\") #remove empty values\n",
    "  pronounce_dic_tran[key] = val #reassign\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2375b33f-6eb3-47e9-a128-2bb6fc8e0e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': ['AH0'],\n",
       " 'AS': ['EY1', 'Z'],\n",
       " 'A42128': ['EY1',\n",
       "  'F',\n",
       "  'AO1',\n",
       "  'R',\n",
       "  'T',\n",
       "  'UW1',\n",
       "  'W',\n",
       "  'AH1',\n",
       "  'N',\n",
       "  'T',\n",
       "  'UW1',\n",
       "  'EY1',\n",
       "  'T'],\n",
       " 'AA': ['EY2', 'EY1']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list first 4 items\n",
    "dict(list(pronounce_dic_tran.items())[0:4]) #does not work sometimes?\n",
    "#they are cleaned\n",
    "\n",
    "#counter = 0\n",
    "\n",
    "#for key, val in pronounce_dic_tran.items():\n",
    "#    print(key)\n",
    "#    print(val)\n",
    "#    counter += 1\n",
    "#    if counter == 5:\n",
    "#        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75f6b5f-8404-4c6d-a105-4d12b1e5d865",
   "metadata": {},
   "source": [
    "## Count number of syllables per word\n",
    "\n",
    "1. Count the number of digits in each dictionary element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12fe58e9-0a8b-4630-8b96-c658ad7e1269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>pronounciations</th>\n",
       "      <th>num_syllables</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>[AH0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AS</td>\n",
       "      <td>[EY1, Z]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A42128</td>\n",
       "      <td>[EY1, F, AO1, R, T, UW1, W, AH1, N, T, UW1, EY...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AA</td>\n",
       "      <td>[EY2, EY1]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAA</td>\n",
       "      <td>[T, R, IH2, P, AH0, L, EY1]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121748</th>\n",
       "      <td>ZYSK</td>\n",
       "      <td>[Z, IH1, S, K]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121749</th>\n",
       "      <td>ZYSKOWSKI</td>\n",
       "      <td>[Z, IH0, S, K, AO1, F, S, K, IY0]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121750</th>\n",
       "      <td>ZYUGANOV</td>\n",
       "      <td>[Z, Y, UW1, G, AA0, N, AA0, V]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121751</th>\n",
       "      <td>ZYUGANOVS</td>\n",
       "      <td>[Z, Y, UW1, G, AA0, N, AA0, V, Z]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121752</th>\n",
       "      <td>ZYWICKI</td>\n",
       "      <td>[Z, IH0, W, IH1, K, IY0]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121753 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            words                                    pronounciations  \\\n",
       "0               A                                              [AH0]   \n",
       "1              AS                                           [EY1, Z]   \n",
       "2          A42128  [EY1, F, AO1, R, T, UW1, W, AH1, N, T, UW1, EY...   \n",
       "3              AA                                         [EY2, EY1]   \n",
       "4             AAA                        [T, R, IH2, P, AH0, L, EY1]   \n",
       "...           ...                                                ...   \n",
       "121748       ZYSK                                     [Z, IH1, S, K]   \n",
       "121749  ZYSKOWSKI                  [Z, IH0, S, K, AO1, F, S, K, IY0]   \n",
       "121750   ZYUGANOV                     [Z, Y, UW1, G, AA0, N, AA0, V]   \n",
       "121751  ZYUGANOVS                  [Z, Y, UW1, G, AA0, N, AA0, V, Z]   \n",
       "121752    ZYWICKI                           [Z, IH0, W, IH1, K, IY0]   \n",
       "\n",
       "        num_syllables  \n",
       "0                   1  \n",
       "1                   1  \n",
       "2                   6  \n",
       "3                   2  \n",
       "4                   3  \n",
       "...               ...  \n",
       "121748              1  \n",
       "121749              3  \n",
       "121750              3  \n",
       "121751              3  \n",
       "121752              3  \n",
       "\n",
       "[121753 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# read in vowels from cmu\n",
    "vow = pd.read_csv(\"cmu_phones_vowels.csv\")\n",
    " \n",
    "# convert vowel column to list\n",
    "vowels = vow['vowel'].tolist()\n",
    "\n",
    "words = [] #keep track of all the words in pronunciation dictionary\n",
    "pronounciation = [] #keep track of all the pronunications\n",
    "for i in pronounce_dic_tran:\n",
    "    words.append(i) #put words in list above\n",
    "    pronounciation.append(pronounce_dic_tran[i]) #put pronunciations in list above\n",
    "\n",
    "decoding_df = pd.DataFrame() #create pandas dataframe\n",
    "decoding_df['words'] = words\n",
    "decoding_df['pronounciations'] = pronounciation #add words and pronunciations to dataframe\n",
    "\n",
    "syllables = []\n",
    "\n",
    "for key, value in pronounce_dic_tran.items(): #read cmu dict\n",
    "    #print(value)\n",
    "    \n",
    "    count = 0 #start a count\n",
    "    for val in value:  \n",
    "        #print(v)\n",
    "        if val in vowels: #count the number of vowels in each word (i.e,. syllables)\n",
    "            #print(val)\n",
    "            count += 1\n",
    "            #print(count)\n",
    "\n",
    "    syllables.append(count) #append syllable count\n",
    "\n",
    "decoding_df['num_syllables'] = syllables\n",
    "    \n",
    "decoding_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fa04fa-3fb6-41ca-a0f3-e66bf246b09a",
   "metadata": {},
   "source": [
    "## Count number of letters per word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "274c8a7a-2dd2-4d40-97a4-8e6d03fe3ef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>pronounciations</th>\n",
       "      <th>num_syllables</th>\n",
       "      <th>num_letters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>[AH0]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AS</td>\n",
       "      <td>[EY1, Z]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A42128</td>\n",
       "      <td>[EY1, F, AO1, R, T, UW1, W, AH1, N, T, UW1, EY...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AA</td>\n",
       "      <td>[EY2, EY1]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAA</td>\n",
       "      <td>[T, R, IH2, P, AH0, L, EY1]</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121748</th>\n",
       "      <td>ZYSK</td>\n",
       "      <td>[Z, IH1, S, K]</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121749</th>\n",
       "      <td>ZYSKOWSKI</td>\n",
       "      <td>[Z, IH0, S, K, AO1, F, S, K, IY0]</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121750</th>\n",
       "      <td>ZYUGANOV</td>\n",
       "      <td>[Z, Y, UW1, G, AA0, N, AA0, V]</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121751</th>\n",
       "      <td>ZYUGANOVS</td>\n",
       "      <td>[Z, Y, UW1, G, AA0, N, AA0, V, Z]</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121752</th>\n",
       "      <td>ZYWICKI</td>\n",
       "      <td>[Z, IH0, W, IH1, K, IY0]</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121753 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            words                                    pronounciations  \\\n",
       "0               A                                              [AH0]   \n",
       "1              AS                                           [EY1, Z]   \n",
       "2          A42128  [EY1, F, AO1, R, T, UW1, W, AH1, N, T, UW1, EY...   \n",
       "3              AA                                         [EY2, EY1]   \n",
       "4             AAA                        [T, R, IH2, P, AH0, L, EY1]   \n",
       "...           ...                                                ...   \n",
       "121748       ZYSK                                     [Z, IH1, S, K]   \n",
       "121749  ZYSKOWSKI                  [Z, IH0, S, K, AO1, F, S, K, IY0]   \n",
       "121750   ZYUGANOV                     [Z, Y, UW1, G, AA0, N, AA0, V]   \n",
       "121751  ZYUGANOVS                  [Z, Y, UW1, G, AA0, N, AA0, V, Z]   \n",
       "121752    ZYWICKI                           [Z, IH0, W, IH1, K, IY0]   \n",
       "\n",
       "        num_syllables  num_letters  \n",
       "0                   1            1  \n",
       "1                   1            2  \n",
       "2                   6            6  \n",
       "3                   2            2  \n",
       "4                   3            3  \n",
       "...               ...          ...  \n",
       "121748              1            4  \n",
       "121749              3            9  \n",
       "121750              3            8  \n",
       "121751              3            9  \n",
       "121752              3            7  \n",
       "\n",
       "[121753 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#words_small = words[1055:1065]\n",
    "\n",
    "#print(words_small)\n",
    "\n",
    "letter_per_word = []\n",
    "\n",
    "for word in words:\n",
    "    #print(len(word))\n",
    "    letter_per_word.append(len(word)) #count characters per word\n",
    "    #print(count)\n",
    "    \n",
    "#print(letter_per_word[0:20])\n",
    "\n",
    "decoding_df['num_letters'] = letter_per_word #add to dataframe\n",
    "decoding_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb81677-929f-4654-b91c-8f752c555ce8",
   "metadata": {},
   "source": [
    "## Number of phonemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7edca823-2182-4880-9697-1ebab4101c53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>pronounciations</th>\n",
       "      <th>num_syllables</th>\n",
       "      <th>num_letters</th>\n",
       "      <th>num_phonemes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>[AH0]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AS</td>\n",
       "      <td>[EY1, Z]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A42128</td>\n",
       "      <td>[EY1, F, AO1, R, T, UW1, W, AH1, N, T, UW1, EY...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AA</td>\n",
       "      <td>[EY2, EY1]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAA</td>\n",
       "      <td>[T, R, IH2, P, AH0, L, EY1]</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121748</th>\n",
       "      <td>ZYSK</td>\n",
       "      <td>[Z, IH1, S, K]</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121749</th>\n",
       "      <td>ZYSKOWSKI</td>\n",
       "      <td>[Z, IH0, S, K, AO1, F, S, K, IY0]</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121750</th>\n",
       "      <td>ZYUGANOV</td>\n",
       "      <td>[Z, Y, UW1, G, AA0, N, AA0, V]</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121751</th>\n",
       "      <td>ZYUGANOVS</td>\n",
       "      <td>[Z, Y, UW1, G, AA0, N, AA0, V, Z]</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121752</th>\n",
       "      <td>ZYWICKI</td>\n",
       "      <td>[Z, IH0, W, IH1, K, IY0]</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121753 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            words                                    pronounciations  \\\n",
       "0               A                                              [AH0]   \n",
       "1              AS                                           [EY1, Z]   \n",
       "2          A42128  [EY1, F, AO1, R, T, UW1, W, AH1, N, T, UW1, EY...   \n",
       "3              AA                                         [EY2, EY1]   \n",
       "4             AAA                        [T, R, IH2, P, AH0, L, EY1]   \n",
       "...           ...                                                ...   \n",
       "121748       ZYSK                                     [Z, IH1, S, K]   \n",
       "121749  ZYSKOWSKI                  [Z, IH0, S, K, AO1, F, S, K, IY0]   \n",
       "121750   ZYUGANOV                     [Z, Y, UW1, G, AA0, N, AA0, V]   \n",
       "121751  ZYUGANOVS                  [Z, Y, UW1, G, AA0, N, AA0, V, Z]   \n",
       "121752    ZYWICKI                           [Z, IH0, W, IH1, K, IY0]   \n",
       "\n",
       "        num_syllables  num_letters  num_phonemes  \n",
       "0                   1            1             1  \n",
       "1                   1            2             2  \n",
       "2                   6            6            13  \n",
       "3                   2            2             2  \n",
       "4                   3            3             7  \n",
       "...               ...          ...           ...  \n",
       "121748              1            4             4  \n",
       "121749              3            9             9  \n",
       "121750              3            8             8  \n",
       "121751              3            9             9  \n",
       "121752              3            7             6  \n",
       "\n",
       "[121753 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#small_list_list = pronounciation[1000:1006]\n",
    "#print(small_list_list)\n",
    "\n",
    "phoneme_count = []\n",
    "\n",
    "for list in pronounciation: #use pronunciation list to count phonemes\n",
    "    #print(len(list))\n",
    "    phoneme_count.append(len(list))\n",
    "\n",
    "#print(phoneme_count[0:5])\n",
    "\n",
    "decoding_df['num_phonemes'] = phoneme_count\n",
    "\n",
    "decoding_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede6bd06-00f1-4b29-aed3-3ab4c18a0b6d",
   "metadata": {},
   "source": [
    "## Compute discrepancy \n",
    "\n",
    "basically, differences between the number of characters in a word and the number of phonemes in that word\n",
    "\n",
    "Number phonemes minus number of letters\n",
    "Number of letters/number of phonemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07d3f7e3-fbe1-40ab-865b-53021ce1e0ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>pronounciations</th>\n",
       "      <th>num_syllables</th>\n",
       "      <th>num_letters</th>\n",
       "      <th>num_phonemes</th>\n",
       "      <th>discrepancy_raw</th>\n",
       "      <th>discrepancy_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>[AH0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AS</td>\n",
       "      <td>[EY1, Z]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A42128</td>\n",
       "      <td>[EY1, F, AO1, R, T, UW1, W, AH1, N, T, UW1, EY...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AA</td>\n",
       "      <td>[EY2, EY1]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAA</td>\n",
       "      <td>[T, R, IH2, P, AH0, L, EY1]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121748</th>\n",
       "      <td>ZYSK</td>\n",
       "      <td>[Z, IH1, S, K]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121749</th>\n",
       "      <td>ZYSKOWSKI</td>\n",
       "      <td>[Z, IH0, S, K, AO1, F, S, K, IY0]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121750</th>\n",
       "      <td>ZYUGANOV</td>\n",
       "      <td>[Z, Y, UW1, G, AA0, N, AA0, V]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121751</th>\n",
       "      <td>ZYUGANOVS</td>\n",
       "      <td>[Z, Y, UW1, G, AA0, N, AA0, V, Z]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121752</th>\n",
       "      <td>ZYWICKI</td>\n",
       "      <td>[Z, IH0, W, IH1, K, IY0]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121753 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            words                                    pronounciations  \\\n",
       "0               A                                              [AH0]   \n",
       "1              AS                                           [EY1, Z]   \n",
       "2          A42128  [EY1, F, AO1, R, T, UW1, W, AH1, N, T, UW1, EY...   \n",
       "3              AA                                         [EY2, EY1]   \n",
       "4             AAA                        [T, R, IH2, P, AH0, L, EY1]   \n",
       "...           ...                                                ...   \n",
       "121748       ZYSK                                     [Z, IH1, S, K]   \n",
       "121749  ZYSKOWSKI                  [Z, IH0, S, K, AO1, F, S, K, IY0]   \n",
       "121750   ZYUGANOV                     [Z, Y, UW1, G, AA0, N, AA0, V]   \n",
       "121751  ZYUGANOVS                  [Z, Y, UW1, G, AA0, N, AA0, V, Z]   \n",
       "121752    ZYWICKI                           [Z, IH0, W, IH1, K, IY0]   \n",
       "\n",
       "        num_syllables  num_letters  num_phonemes  discrepancy_raw  \\\n",
       "0                 1.0          1.0           1.0              0.0   \n",
       "1                 1.0          2.0           2.0              0.0   \n",
       "2                 6.0          6.0          13.0              7.0   \n",
       "3                 2.0          2.0           2.0              0.0   \n",
       "4                 3.0          3.0           7.0              4.0   \n",
       "...               ...          ...           ...              ...   \n",
       "121748            1.0          4.0           4.0              0.0   \n",
       "121749            3.0          9.0           9.0              0.0   \n",
       "121750            3.0          8.0           8.0              0.0   \n",
       "121751            3.0          9.0           9.0              0.0   \n",
       "121752            3.0          7.0           6.0             -1.0   \n",
       "\n",
       "        discrepancy_ratio  \n",
       "0                1.000000  \n",
       "1                1.000000  \n",
       "2                2.166667  \n",
       "3                1.000000  \n",
       "4                2.333333  \n",
       "...                   ...  \n",
       "121748           1.000000  \n",
       "121749           1.000000  \n",
       "121750           1.000000  \n",
       "121751           1.000000  \n",
       "121752           0.857143  \n",
       "\n",
       "[121753 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#change counts to floats\n",
    "decoding_df['num_syllables'] = decoding_df['num_syllables'].astype(float)\n",
    "decoding_df['num_letters'] = decoding_df['num_letters'].astype(float)\n",
    "decoding_df['num_phonemes'] = decoding_df['num_phonemes'].astype(float)\n",
    "\n",
    "decoding_df['discrepancy_raw'] = decoding_df.apply(lambda row: row.num_phonemes - row.num_letters, axis=1)\n",
    "#number of phonemes minus number of letters\n",
    "\n",
    "#use safe_divide function in .apply function for potential division by 0 problems\n",
    "decoding_df['discrepancy_ratio'] = decoding_df.apply(lambda row: safe_divide(row.num_phonemes,row.num_letters), axis=1)\n",
    "#number of phonemes/number of letters\n",
    "\n",
    "decoding_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d9f265-b73f-484e-99d9-5dd9fd42bbb1",
   "metadata": {},
   "source": [
    "## Compute Average Syllable Length\n",
    "\n",
    "number of letters/Number of syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c22ac210-24a2-42f1-9ef7-f68c0210f25d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>pronounciations</th>\n",
       "      <th>num_syllables</th>\n",
       "      <th>num_letters</th>\n",
       "      <th>num_phonemes</th>\n",
       "      <th>discrepancy_raw</th>\n",
       "      <th>discrepancy_ratio</th>\n",
       "      <th>avg_syllable_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>[AH0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AS</td>\n",
       "      <td>[EY1, Z]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A42128</td>\n",
       "      <td>[EY1, F, AO1, R, T, UW1, W, AH1, N, T, UW1, EY...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AA</td>\n",
       "      <td>[EY2, EY1]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAA</td>\n",
       "      <td>[T, R, IH2, P, AH0, L, EY1]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121748</th>\n",
       "      <td>ZYSK</td>\n",
       "      <td>[Z, IH1, S, K]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121749</th>\n",
       "      <td>ZYSKOWSKI</td>\n",
       "      <td>[Z, IH0, S, K, AO1, F, S, K, IY0]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121750</th>\n",
       "      <td>ZYUGANOV</td>\n",
       "      <td>[Z, Y, UW1, G, AA0, N, AA0, V]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121751</th>\n",
       "      <td>ZYUGANOVS</td>\n",
       "      <td>[Z, Y, UW1, G, AA0, N, AA0, V, Z]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121752</th>\n",
       "      <td>ZYWICKI</td>\n",
       "      <td>[Z, IH0, W, IH1, K, IY0]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>2.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121753 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            words                                    pronounciations  \\\n",
       "0               A                                              [AH0]   \n",
       "1              AS                                           [EY1, Z]   \n",
       "2          A42128  [EY1, F, AO1, R, T, UW1, W, AH1, N, T, UW1, EY...   \n",
       "3              AA                                         [EY2, EY1]   \n",
       "4             AAA                        [T, R, IH2, P, AH0, L, EY1]   \n",
       "...           ...                                                ...   \n",
       "121748       ZYSK                                     [Z, IH1, S, K]   \n",
       "121749  ZYSKOWSKI                  [Z, IH0, S, K, AO1, F, S, K, IY0]   \n",
       "121750   ZYUGANOV                     [Z, Y, UW1, G, AA0, N, AA0, V]   \n",
       "121751  ZYUGANOVS                  [Z, Y, UW1, G, AA0, N, AA0, V, Z]   \n",
       "121752    ZYWICKI                           [Z, IH0, W, IH1, K, IY0]   \n",
       "\n",
       "        num_syllables  num_letters  num_phonemes  discrepancy_raw  \\\n",
       "0                 1.0          1.0           1.0              0.0   \n",
       "1                 1.0          2.0           2.0              0.0   \n",
       "2                 6.0          6.0          13.0              7.0   \n",
       "3                 2.0          2.0           2.0              0.0   \n",
       "4                 3.0          3.0           7.0              4.0   \n",
       "...               ...          ...           ...              ...   \n",
       "121748            1.0          4.0           4.0              0.0   \n",
       "121749            3.0          9.0           9.0              0.0   \n",
       "121750            3.0          8.0           8.0              0.0   \n",
       "121751            3.0          9.0           9.0              0.0   \n",
       "121752            3.0          7.0           6.0             -1.0   \n",
       "\n",
       "        discrepancy_ratio  avg_syllable_length  \n",
       "0                1.000000             1.000000  \n",
       "1                1.000000             2.000000  \n",
       "2                2.166667             1.000000  \n",
       "3                1.000000             1.000000  \n",
       "4                2.333333             1.000000  \n",
       "...                   ...                  ...  \n",
       "121748           1.000000             4.000000  \n",
       "121749           1.000000             3.000000  \n",
       "121750           1.000000             2.666667  \n",
       "121751           1.000000             3.000000  \n",
       "121752           0.857143             2.333333  \n",
       "\n",
       "[121753 rows x 8 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use safe_divide function in .apply function for potential division by 0 problems\n",
    "decoding_df['avg_syllable_length'] = decoding_df.apply(lambda row: safe_divide(row.num_letters,row.num_syllables), axis=1)\n",
    "\n",
    "\n",
    "decoding_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f661aed-9c65-4e83-9e7a-387d4de08ea3",
   "metadata": {},
   "source": [
    "## Count up blends\n",
    "\n",
    "combinations of two or three consonants which, when pronounced, blend into sounds which still retain elements of the individual consonants\n",
    "\n",
    "Need character counts for vowels and consonant (i.e., how many vowels and how many consonants per word)\n",
    "\n",
    "Then need phoneme counts for vowels and consonants\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb7e992-c85e-4185-840f-a72c0bb78fe1",
   "metadata": {},
   "source": [
    "### Start with character counts\n",
    "\n",
    "Counts for vowels and phonemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18665c32-c5fe-4d65-9889-bbc798a1fb1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>pronounciations</th>\n",
       "      <th>num_syllables</th>\n",
       "      <th>num_letters</th>\n",
       "      <th>num_phonemes</th>\n",
       "      <th>discrepancy_raw</th>\n",
       "      <th>discrepancy_ratio</th>\n",
       "      <th>avg_syllable_length</th>\n",
       "      <th>num_consonants_characters</th>\n",
       "      <th>num_vowel_characters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>[AH0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AS</td>\n",
       "      <td>[EY1, Z]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A42128</td>\n",
       "      <td>[EY1, F, AO1, R, T, UW1, W, AH1, N, T, UW1, EY...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AA</td>\n",
       "      <td>[EY2, EY1]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAA</td>\n",
       "      <td>[T, R, IH2, P, AH0, L, EY1]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121748</th>\n",
       "      <td>ZYSK</td>\n",
       "      <td>[Z, IH1, S, K]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121749</th>\n",
       "      <td>ZYSKOWSKI</td>\n",
       "      <td>[Z, IH0, S, K, AO1, F, S, K, IY0]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121750</th>\n",
       "      <td>ZYUGANOV</td>\n",
       "      <td>[Z, Y, UW1, G, AA0, N, AA0, V]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121751</th>\n",
       "      <td>ZYUGANOVS</td>\n",
       "      <td>[Z, Y, UW1, G, AA0, N, AA0, V, Z]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121752</th>\n",
       "      <td>ZYWICKI</td>\n",
       "      <td>[Z, IH0, W, IH1, K, IY0]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121753 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            words                                    pronounciations  \\\n",
       "0               A                                              [AH0]   \n",
       "1              AS                                           [EY1, Z]   \n",
       "2          A42128  [EY1, F, AO1, R, T, UW1, W, AH1, N, T, UW1, EY...   \n",
       "3              AA                                         [EY2, EY1]   \n",
       "4             AAA                        [T, R, IH2, P, AH0, L, EY1]   \n",
       "...           ...                                                ...   \n",
       "121748       ZYSK                                     [Z, IH1, S, K]   \n",
       "121749  ZYSKOWSKI                  [Z, IH0, S, K, AO1, F, S, K, IY0]   \n",
       "121750   ZYUGANOV                     [Z, Y, UW1, G, AA0, N, AA0, V]   \n",
       "121751  ZYUGANOVS                  [Z, Y, UW1, G, AA0, N, AA0, V, Z]   \n",
       "121752    ZYWICKI                           [Z, IH0, W, IH1, K, IY0]   \n",
       "\n",
       "        num_syllables  num_letters  num_phonemes  discrepancy_raw  \\\n",
       "0                 1.0          1.0           1.0              0.0   \n",
       "1                 1.0          2.0           2.0              0.0   \n",
       "2                 6.0          6.0          13.0              7.0   \n",
       "3                 2.0          2.0           2.0              0.0   \n",
       "4                 3.0          3.0           7.0              4.0   \n",
       "...               ...          ...           ...              ...   \n",
       "121748            1.0          4.0           4.0              0.0   \n",
       "121749            3.0          9.0           9.0              0.0   \n",
       "121750            3.0          8.0           8.0              0.0   \n",
       "121751            3.0          9.0           9.0              0.0   \n",
       "121752            3.0          7.0           6.0             -1.0   \n",
       "\n",
       "        discrepancy_ratio  avg_syllable_length  num_consonants_characters  \\\n",
       "0                1.000000             1.000000                          0   \n",
       "1                1.000000             2.000000                          1   \n",
       "2                2.166667             1.000000                          5   \n",
       "3                1.000000             1.000000                          0   \n",
       "4                2.333333             1.000000                          0   \n",
       "...                   ...                  ...                        ...   \n",
       "121748           1.000000             4.000000                          3   \n",
       "121749           1.000000             3.000000                          6   \n",
       "121750           1.000000             2.666667                          4   \n",
       "121751           1.000000             3.000000                          5   \n",
       "121752           0.857143             2.333333                          4   \n",
       "\n",
       "        num_vowel_characters  \n",
       "0                          1  \n",
       "1                          1  \n",
       "2                          1  \n",
       "3                          2  \n",
       "4                          3  \n",
       "...                      ...  \n",
       "121748                     1  \n",
       "121749                     3  \n",
       "121750                     4  \n",
       "121751                     4  \n",
       "121752                     3  \n",
       "\n",
       "[121753 rows x 10 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prac_words = words[11000:11005]\n",
    "#print(prac_words)\n",
    "\n",
    "#list of character vowels\n",
    "chr_vowels = ['A', 'E', 'I', 'O', 'U', 'Y']\n",
    "#print(chr_vowels)\n",
    "\n",
    "#count consonant characters per word\n",
    "\n",
    "cons_char_count_words = [] #holder for list of lists for consonant counts\n",
    "\n",
    "for w in words:\n",
    "    cons_char_words = []\n",
    "    for char in w:\n",
    "        #print(char)\n",
    "        if char not in chr_vowels: #if not a vowel\n",
    "            #print(char)\n",
    "            cons_char_words.append(char) #append to intermediate list\n",
    "    #print(char_words)\n",
    "    cons_char_count_words.append(len(cons_char_words)) #append length of of list to list of list        \n",
    "\n",
    "#print(cons_char_count_words)    \n",
    "\n",
    "\n",
    "#count number of vowel characters per word\n",
    "\n",
    "vowel_char_count_words = [] #holder for list of lists for vowel counts\n",
    "\n",
    "for w in words:\n",
    "    vowel_char_words = []\n",
    "    for char in w:\n",
    "        #print(char)\n",
    "        if char in chr_vowels: #if it is a vowel\n",
    "            #print(char)\n",
    "            vowel_char_words.append(char)\n",
    "    #print(char_words)\n",
    "    vowel_char_count_words.append(len(vowel_char_words)) #append length of of list to list of list        \n",
    "\n",
    "#print(vowel_char_count_words)    \n",
    "\n",
    "\n",
    "\n",
    "decoding_df['num_consonants_characters'] = cons_char_count_words\n",
    "decoding_df['num_vowel_characters'] = vowel_char_count_words\n",
    "decoding_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e07bbb3-e18f-4bbb-a451-cb1de1fb2c84",
   "metadata": {},
   "source": [
    "### Second, get phoneme counts\n",
    "\n",
    "for vowels and for consonants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77a7f090-cb3a-48bb-97af-9f70ed018a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>pronounciations</th>\n",
       "      <th>num_syllables</th>\n",
       "      <th>num_letters</th>\n",
       "      <th>num_phonemes</th>\n",
       "      <th>discrepancy_raw</th>\n",
       "      <th>discrepancy_ratio</th>\n",
       "      <th>avg_syllable_length</th>\n",
       "      <th>num_consonants_characters</th>\n",
       "      <th>num_vowel_characters</th>\n",
       "      <th>num_consonants_phonemes</th>\n",
       "      <th>num_vowel_phonemes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>[AH0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AS</td>\n",
       "      <td>[EY1, Z]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A42128</td>\n",
       "      <td>[EY1, F, AO1, R, T, UW1, W, AH1, N, T, UW1, EY...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AA</td>\n",
       "      <td>[EY2, EY1]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAA</td>\n",
       "      <td>[T, R, IH2, P, AH0, L, EY1]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121748</th>\n",
       "      <td>ZYSK</td>\n",
       "      <td>[Z, IH1, S, K]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121749</th>\n",
       "      <td>ZYSKOWSKI</td>\n",
       "      <td>[Z, IH0, S, K, AO1, F, S, K, IY0]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121750</th>\n",
       "      <td>ZYUGANOV</td>\n",
       "      <td>[Z, Y, UW1, G, AA0, N, AA0, V]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121751</th>\n",
       "      <td>ZYUGANOVS</td>\n",
       "      <td>[Z, Y, UW1, G, AA0, N, AA0, V, Z]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121752</th>\n",
       "      <td>ZYWICKI</td>\n",
       "      <td>[Z, IH0, W, IH1, K, IY0]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121753 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            words                                    pronounciations  \\\n",
       "0               A                                              [AH0]   \n",
       "1              AS                                           [EY1, Z]   \n",
       "2          A42128  [EY1, F, AO1, R, T, UW1, W, AH1, N, T, UW1, EY...   \n",
       "3              AA                                         [EY2, EY1]   \n",
       "4             AAA                        [T, R, IH2, P, AH0, L, EY1]   \n",
       "...           ...                                                ...   \n",
       "121748       ZYSK                                     [Z, IH1, S, K]   \n",
       "121749  ZYSKOWSKI                  [Z, IH0, S, K, AO1, F, S, K, IY0]   \n",
       "121750   ZYUGANOV                     [Z, Y, UW1, G, AA0, N, AA0, V]   \n",
       "121751  ZYUGANOVS                  [Z, Y, UW1, G, AA0, N, AA0, V, Z]   \n",
       "121752    ZYWICKI                           [Z, IH0, W, IH1, K, IY0]   \n",
       "\n",
       "        num_syllables  num_letters  num_phonemes  discrepancy_raw  \\\n",
       "0                 1.0          1.0           1.0              0.0   \n",
       "1                 1.0          2.0           2.0              0.0   \n",
       "2                 6.0          6.0          13.0              7.0   \n",
       "3                 2.0          2.0           2.0              0.0   \n",
       "4                 3.0          3.0           7.0              4.0   \n",
       "...               ...          ...           ...              ...   \n",
       "121748            1.0          4.0           4.0              0.0   \n",
       "121749            3.0          9.0           9.0              0.0   \n",
       "121750            3.0          8.0           8.0              0.0   \n",
       "121751            3.0          9.0           9.0              0.0   \n",
       "121752            3.0          7.0           6.0             -1.0   \n",
       "\n",
       "        discrepancy_ratio  avg_syllable_length  num_consonants_characters  \\\n",
       "0                1.000000             1.000000                          0   \n",
       "1                1.000000             2.000000                          1   \n",
       "2                2.166667             1.000000                          5   \n",
       "3                1.000000             1.000000                          0   \n",
       "4                2.333333             1.000000                          0   \n",
       "...                   ...                  ...                        ...   \n",
       "121748           1.000000             4.000000                          3   \n",
       "121749           1.000000             3.000000                          6   \n",
       "121750           1.000000             2.666667                          4   \n",
       "121751           1.000000             3.000000                          5   \n",
       "121752           0.857143             2.333333                          4   \n",
       "\n",
       "        num_vowel_characters  num_consonants_phonemes  num_vowel_phonemes  \n",
       "0                          1                        0                   1  \n",
       "1                          1                        1                   1  \n",
       "2                          1                        7                   6  \n",
       "3                          2                        0                   2  \n",
       "4                          3                        4                   3  \n",
       "...                      ...                      ...                 ...  \n",
       "121748                     1                        3                   1  \n",
       "121749                     3                        6                   3  \n",
       "121750                     4                        5                   3  \n",
       "121751                     4                        6                   3  \n",
       "121752                     3                        3                   3  \n",
       "\n",
       "[121753 rows x 12 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prac_words = pronounciation[0:11]\n",
    "#print(prac_words)\n",
    "\n",
    "#list of phoneme vowels from Pronunciation dictionary\n",
    "#print(vowels)\n",
    "\n",
    "#count consonant phonemes per word\n",
    "\n",
    "cons_phon_count_words = [] #holder for list of lists for consonant counts\n",
    "\n",
    "for w in pronounciation:\n",
    "    #print(w)\n",
    "    cons_phon_words = []\n",
    "    for phon in w:\n",
    "        #print(phon)\n",
    "        if phon not in vowels: #these are vowels from the Pronunciation dictionary\n",
    "            #print(phon)\n",
    "            cons_phon_words.append(phon)\n",
    "    #print(cons_phon_words)\n",
    "    cons_phon_count_words.append(len(cons_phon_words)) #append length of of list to list of list        \n",
    "\n",
    "#print(cons_phon_count_words)    \n",
    "\n",
    "#count vowel phonemes per word\n",
    "\n",
    "\n",
    "vowel_phon_count_words = [] #holder for list of lists for consonant counts\n",
    "\n",
    "for w in pronounciation:\n",
    "    #print(w)\n",
    "    vowel_phon_words = []\n",
    "    for phon in w:\n",
    "        #print(phon)\n",
    "        if phon in vowels:\n",
    "            #print(phon)\n",
    "            vowel_phon_words.append(phon)\n",
    "    #print(vowel_phon_words)\n",
    "    #vowel_phon_count_words.append(vowel_phon_words) #append length of of list to list of list        \n",
    "    vowel_phon_count_words.append(len(vowel_phon_words)) #append length of of list to list of list        \n",
    "\n",
    "#print(vowel_phon_count_words)    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "decoding_df['num_consonants_phonemes'] = cons_phon_count_words\n",
    "decoding_df['num_vowel_phonemes'] = vowel_phon_count_words\n",
    "\n",
    "decoding_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0a0be4-c6b5-4208-ab24-be466f06773f",
   "metadata": {},
   "source": [
    "### Lastly, count the following\n",
    "\n",
    "- Number of characters consonants/number of consonant phonemes\n",
    "- Number of character vowels/number of vowel phonemes\n",
    "- Number of letters/number of phonemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca8d245f-6782-440c-98c9-c317d363b267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>pronounciations</th>\n",
       "      <th>num_syllables</th>\n",
       "      <th>num_letters</th>\n",
       "      <th>num_phonemes</th>\n",
       "      <th>discrepancy_raw</th>\n",
       "      <th>discrepancy_ratio</th>\n",
       "      <th>avg_syllable_length</th>\n",
       "      <th>num_consonants_characters</th>\n",
       "      <th>num_vowel_characters</th>\n",
       "      <th>num_consonants_phonemes</th>\n",
       "      <th>num_vowel_phonemes</th>\n",
       "      <th>avg_phonemes_per_character_consonants</th>\n",
       "      <th>avg_phonemes_per_character_vowels</th>\n",
       "      <th>avg_phonemes_per_character_all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50000</th>\n",
       "      <td>HOBBS</td>\n",
       "      <td>[HH, AA1, B, Z]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50001</th>\n",
       "      <td>HOBBY</td>\n",
       "      <td>[HH, AA1, B, IY0]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50002</th>\n",
       "      <td>HOBBYIST</td>\n",
       "      <td>[HH, AA1, B, IY0, IH0, S, T]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50003</th>\n",
       "      <td>HOBBYISTS</td>\n",
       "      <td>[HH, AA1, B, IY0, IH0, S, T, S]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50004</th>\n",
       "      <td>HOBDAY</td>\n",
       "      <td>[HH, AA1, B, D, EY2]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50005</th>\n",
       "      <td>HOBDY</td>\n",
       "      <td>[HH, AA1, B, D, IY0]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50006</th>\n",
       "      <td>HOBEN</td>\n",
       "      <td>[HH, AA1, B, AH0, N]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50007</th>\n",
       "      <td>HOBERG</td>\n",
       "      <td>[HH, OW1, B, ER0, G]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50008</th>\n",
       "      <td>HOBERMAN</td>\n",
       "      <td>[HH, OW1, B, ER0, M, AH0, N]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50009</th>\n",
       "      <td>HOBERT</td>\n",
       "      <td>[HH, AA1, B, ER0, T]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50010</th>\n",
       "      <td>HOBGOOD</td>\n",
       "      <td>[HH, AA1, B, G, UH2, D]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50011</th>\n",
       "      <td>HOBIN</td>\n",
       "      <td>[HH, OW1, B, IH0, N]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50012</th>\n",
       "      <td>HOBLIT</td>\n",
       "      <td>[HH, AA1, B, L, IH0, T]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50013</th>\n",
       "      <td>HOBNAIL</td>\n",
       "      <td>[HH, AA1, B, N, EY2, L]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50014</th>\n",
       "      <td>HOBNOB</td>\n",
       "      <td>[HH, AA1, B, N, AA2, B]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50015</th>\n",
       "      <td>HOBNOBBING</td>\n",
       "      <td>[HH, AA1, B, N, AA2, B, IH0, NG]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50016</th>\n",
       "      <td>HOBO</td>\n",
       "      <td>[HH, OW1, B, OW0]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50017</th>\n",
       "      <td>HOBOES</td>\n",
       "      <td>[HH, OW1, B, OW0, Z]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50018</th>\n",
       "      <td>HOBOKEN</td>\n",
       "      <td>[HH, OW1, B, OW0, K, AH0, N]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50019</th>\n",
       "      <td>HOBS</td>\n",
       "      <td>[HH, AA1, B, Z]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            words                   pronounciations  num_syllables  \\\n",
       "50000       HOBBS                   [HH, AA1, B, Z]            1.0   \n",
       "50001       HOBBY                 [HH, AA1, B, IY0]            2.0   \n",
       "50002    HOBBYIST      [HH, AA1, B, IY0, IH0, S, T]            3.0   \n",
       "50003   HOBBYISTS   [HH, AA1, B, IY0, IH0, S, T, S]            3.0   \n",
       "50004      HOBDAY              [HH, AA1, B, D, EY2]            2.0   \n",
       "50005       HOBDY              [HH, AA1, B, D, IY0]            2.0   \n",
       "50006       HOBEN              [HH, AA1, B, AH0, N]            2.0   \n",
       "50007      HOBERG              [HH, OW1, B, ER0, G]            2.0   \n",
       "50008    HOBERMAN      [HH, OW1, B, ER0, M, AH0, N]            3.0   \n",
       "50009      HOBERT              [HH, AA1, B, ER0, T]            2.0   \n",
       "50010     HOBGOOD           [HH, AA1, B, G, UH2, D]            2.0   \n",
       "50011       HOBIN              [HH, OW1, B, IH0, N]            2.0   \n",
       "50012      HOBLIT           [HH, AA1, B, L, IH0, T]            2.0   \n",
       "50013     HOBNAIL           [HH, AA1, B, N, EY2, L]            2.0   \n",
       "50014      HOBNOB           [HH, AA1, B, N, AA2, B]            2.0   \n",
       "50015  HOBNOBBING  [HH, AA1, B, N, AA2, B, IH0, NG]            3.0   \n",
       "50016        HOBO                 [HH, OW1, B, OW0]            2.0   \n",
       "50017      HOBOES              [HH, OW1, B, OW0, Z]            2.0   \n",
       "50018     HOBOKEN      [HH, OW1, B, OW0, K, AH0, N]            3.0   \n",
       "50019        HOBS                   [HH, AA1, B, Z]            1.0   \n",
       "\n",
       "       num_letters  num_phonemes  discrepancy_raw  discrepancy_ratio  \\\n",
       "50000          5.0           4.0             -1.0           0.800000   \n",
       "50001          5.0           4.0             -1.0           0.800000   \n",
       "50002          8.0           7.0             -1.0           0.875000   \n",
       "50003          9.0           8.0             -1.0           0.888889   \n",
       "50004          6.0           5.0             -1.0           0.833333   \n",
       "50005          5.0           5.0              0.0           1.000000   \n",
       "50006          5.0           5.0              0.0           1.000000   \n",
       "50007          6.0           5.0             -1.0           0.833333   \n",
       "50008          8.0           7.0             -1.0           0.875000   \n",
       "50009          6.0           5.0             -1.0           0.833333   \n",
       "50010          7.0           6.0             -1.0           0.857143   \n",
       "50011          5.0           5.0              0.0           1.000000   \n",
       "50012          6.0           6.0              0.0           1.000000   \n",
       "50013          7.0           6.0             -1.0           0.857143   \n",
       "50014          6.0           6.0              0.0           1.000000   \n",
       "50015         10.0           8.0             -2.0           0.800000   \n",
       "50016          4.0           4.0              0.0           1.000000   \n",
       "50017          6.0           5.0             -1.0           0.833333   \n",
       "50018          7.0           7.0              0.0           1.000000   \n",
       "50019          4.0           4.0              0.0           1.000000   \n",
       "\n",
       "       avg_syllable_length  num_consonants_characters  num_vowel_characters  \\\n",
       "50000             5.000000                          4                     1   \n",
       "50001             2.500000                          3                     2   \n",
       "50002             2.666667                          5                     3   \n",
       "50003             3.000000                          6                     3   \n",
       "50004             3.000000                          3                     3   \n",
       "50005             2.500000                          3                     2   \n",
       "50006             2.500000                          3                     2   \n",
       "50007             3.000000                          4                     2   \n",
       "50008             2.666667                          5                     3   \n",
       "50009             3.000000                          4                     2   \n",
       "50010             3.500000                          4                     3   \n",
       "50011             2.500000                          3                     2   \n",
       "50012             3.000000                          4                     2   \n",
       "50013             3.500000                          4                     3   \n",
       "50014             3.000000                          4                     2   \n",
       "50015             3.333333                          7                     3   \n",
       "50016             2.000000                          2                     2   \n",
       "50017             3.000000                          3                     3   \n",
       "50018             2.333333                          4                     3   \n",
       "50019             4.000000                          3                     1   \n",
       "\n",
       "       num_consonants_phonemes  num_vowel_phonemes  \\\n",
       "50000                        3                   1   \n",
       "50001                        2                   2   \n",
       "50002                        4                   3   \n",
       "50003                        5                   3   \n",
       "50004                        3                   2   \n",
       "50005                        3                   2   \n",
       "50006                        3                   2   \n",
       "50007                        3                   2   \n",
       "50008                        4                   3   \n",
       "50009                        3                   2   \n",
       "50010                        4                   2   \n",
       "50011                        3                   2   \n",
       "50012                        4                   2   \n",
       "50013                        4                   2   \n",
       "50014                        4                   2   \n",
       "50015                        5                   3   \n",
       "50016                        2                   2   \n",
       "50017                        3                   2   \n",
       "50018                        4                   3   \n",
       "50019                        3                   1   \n",
       "\n",
       "       avg_phonemes_per_character_consonants  \\\n",
       "50000                               1.333333   \n",
       "50001                               1.500000   \n",
       "50002                               1.250000   \n",
       "50003                               1.200000   \n",
       "50004                               1.000000   \n",
       "50005                               1.000000   \n",
       "50006                               1.000000   \n",
       "50007                               1.333333   \n",
       "50008                               1.250000   \n",
       "50009                               1.333333   \n",
       "50010                               1.000000   \n",
       "50011                               1.000000   \n",
       "50012                               1.000000   \n",
       "50013                               1.000000   \n",
       "50014                               1.000000   \n",
       "50015                               1.400000   \n",
       "50016                               1.000000   \n",
       "50017                               1.000000   \n",
       "50018                               1.000000   \n",
       "50019                               1.000000   \n",
       "\n",
       "       avg_phonemes_per_character_vowels  avg_phonemes_per_character_all  \n",
       "50000                                1.0                        1.250000  \n",
       "50001                                1.0                        1.250000  \n",
       "50002                                1.0                        1.142857  \n",
       "50003                                1.0                        1.125000  \n",
       "50004                                1.5                        1.200000  \n",
       "50005                                1.0                        1.000000  \n",
       "50006                                1.0                        1.000000  \n",
       "50007                                1.0                        1.200000  \n",
       "50008                                1.0                        1.142857  \n",
       "50009                                1.0                        1.200000  \n",
       "50010                                1.5                        1.166667  \n",
       "50011                                1.0                        1.000000  \n",
       "50012                                1.0                        1.000000  \n",
       "50013                                1.5                        1.166667  \n",
       "50014                                1.0                        1.000000  \n",
       "50015                                1.0                        1.250000  \n",
       "50016                                1.0                        1.000000  \n",
       "50017                                1.5                        1.200000  \n",
       "50018                                1.0                        1.000000  \n",
       "50019                                1.0                        1.000000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#average phonemes per character (consonants)\n",
    "#average phonemes per character (vowel)\n",
    "#average phonemes per character (all)\n",
    "\n",
    "\n",
    "#use safe_divide function in .apply function for potential division by 0 problems\n",
    "\n",
    "decoding_df['avg_phonemes_per_character_consonants'] = decoding_df.apply(lambda row: safe_divide(row.num_consonants_characters, row.num_consonants_phonemes), axis=1)\n",
    "decoding_df['avg_phonemes_per_character_vowels'] = decoding_df.apply(lambda row: safe_divide(row.num_vowel_characters, row.num_vowel_phonemes), axis=1)\n",
    "#this is the reverse of discrepancy ratio\n",
    "decoding_df['avg_phonemes_per_character_all'] = decoding_df.apply(lambda row: safe_divide(row.num_letters, row.num_phonemes), axis=1)\n",
    "\n",
    "\n",
    "decoding_df[50000:50020]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad7bba25-7a6b-43c9-9507-79725dbb1f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>pronounciations</th>\n",
       "      <th>num_syllables</th>\n",
       "      <th>num_letters</th>\n",
       "      <th>num_phonemes</th>\n",
       "      <th>discrepancy_raw</th>\n",
       "      <th>discrepancy_ratio</th>\n",
       "      <th>avg_syllable_length</th>\n",
       "      <th>num_consonants_characters</th>\n",
       "      <th>num_vowel_characters</th>\n",
       "      <th>num_consonants_phonemes</th>\n",
       "      <th>num_vowel_phonemes</th>\n",
       "      <th>avg_phonemes_per_character_consonants</th>\n",
       "      <th>avg_phonemes_per_character_vowels</th>\n",
       "      <th>avg_phonemes_per_character_all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>[AH0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AS</td>\n",
       "      <td>[EY1, Z]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A42128</td>\n",
       "      <td>[EY1, F, AO1, R, T, UW1, W, AH1, N, T, UW1, EY...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.461538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AA</td>\n",
       "      <td>[EY2, EY1]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAA</td>\n",
       "      <td>[T, R, IH2, P, AH0, L, EY1]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121748</th>\n",
       "      <td>ZYSK</td>\n",
       "      <td>[Z, IH1, S, K]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121749</th>\n",
       "      <td>ZYSKOWSKI</td>\n",
       "      <td>[Z, IH0, S, K, AO1, F, S, K, IY0]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121750</th>\n",
       "      <td>ZYUGANOV</td>\n",
       "      <td>[Z, Y, UW1, G, AA0, N, AA0, V]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121751</th>\n",
       "      <td>ZYUGANOVS</td>\n",
       "      <td>[Z, Y, UW1, G, AA0, N, AA0, V, Z]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121752</th>\n",
       "      <td>ZYWICKI</td>\n",
       "      <td>[Z, IH0, W, IH1, K, IY0]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121753 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            words                                    pronounciations  \\\n",
       "0               A                                              [AH0]   \n",
       "1              AS                                           [EY1, Z]   \n",
       "2          A42128  [EY1, F, AO1, R, T, UW1, W, AH1, N, T, UW1, EY...   \n",
       "3              AA                                         [EY2, EY1]   \n",
       "4             AAA                        [T, R, IH2, P, AH0, L, EY1]   \n",
       "...           ...                                                ...   \n",
       "121748       ZYSK                                     [Z, IH1, S, K]   \n",
       "121749  ZYSKOWSKI                  [Z, IH0, S, K, AO1, F, S, K, IY0]   \n",
       "121750   ZYUGANOV                     [Z, Y, UW1, G, AA0, N, AA0, V]   \n",
       "121751  ZYUGANOVS                  [Z, Y, UW1, G, AA0, N, AA0, V, Z]   \n",
       "121752    ZYWICKI                           [Z, IH0, W, IH1, K, IY0]   \n",
       "\n",
       "        num_syllables  num_letters  num_phonemes  discrepancy_raw  \\\n",
       "0                 1.0          1.0           1.0              0.0   \n",
       "1                 1.0          2.0           2.0              0.0   \n",
       "2                 6.0          6.0          13.0              7.0   \n",
       "3                 2.0          2.0           2.0              0.0   \n",
       "4                 3.0          3.0           7.0              4.0   \n",
       "...               ...          ...           ...              ...   \n",
       "121748            1.0          4.0           4.0              0.0   \n",
       "121749            3.0          9.0           9.0              0.0   \n",
       "121750            3.0          8.0           8.0              0.0   \n",
       "121751            3.0          9.0           9.0              0.0   \n",
       "121752            3.0          7.0           6.0             -1.0   \n",
       "\n",
       "        discrepancy_ratio  avg_syllable_length  num_consonants_characters  \\\n",
       "0                1.000000             1.000000                          0   \n",
       "1                1.000000             2.000000                          1   \n",
       "2                2.166667             1.000000                          5   \n",
       "3                1.000000             1.000000                          0   \n",
       "4                2.333333             1.000000                          0   \n",
       "...                   ...                  ...                        ...   \n",
       "121748           1.000000             4.000000                          3   \n",
       "121749           1.000000             3.000000                          6   \n",
       "121750           1.000000             2.666667                          4   \n",
       "121751           1.000000             3.000000                          5   \n",
       "121752           0.857143             2.333333                          4   \n",
       "\n",
       "        num_vowel_characters  num_consonants_phonemes  num_vowel_phonemes  \\\n",
       "0                          1                        0                   1   \n",
       "1                          1                        1                   1   \n",
       "2                          1                        7                   6   \n",
       "3                          2                        0                   2   \n",
       "4                          3                        4                   3   \n",
       "...                      ...                      ...                 ...   \n",
       "121748                     1                        3                   1   \n",
       "121749                     3                        6                   3   \n",
       "121750                     4                        5                   3   \n",
       "121751                     4                        6                   3   \n",
       "121752                     3                        3                   3   \n",
       "\n",
       "        avg_phonemes_per_character_consonants  \\\n",
       "0                                    0.000000   \n",
       "1                                    1.000000   \n",
       "2                                    0.714286   \n",
       "3                                    0.000000   \n",
       "4                                    0.000000   \n",
       "...                                       ...   \n",
       "121748                               1.000000   \n",
       "121749                               1.000000   \n",
       "121750                               0.800000   \n",
       "121751                               0.833333   \n",
       "121752                               1.333333   \n",
       "\n",
       "        avg_phonemes_per_character_vowels  avg_phonemes_per_character_all  \n",
       "0                                1.000000                        1.000000  \n",
       "1                                1.000000                        1.000000  \n",
       "2                                0.166667                        0.461538  \n",
       "3                                1.000000                        1.000000  \n",
       "4                                1.000000                        0.428571  \n",
       "...                                   ...                             ...  \n",
       "121748                           1.000000                        1.000000  \n",
       "121749                           1.000000                        1.000000  \n",
       "121750                           1.333333                        1.000000  \n",
       "121751                           1.333333                        1.000000  \n",
       "121752                           1.000000                        1.166667  \n",
       "\n",
       "[121753 rows x 15 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoding_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98a03b5-ad99-4de1-a7ee-156fc72fc2c3",
   "metadata": {},
   "source": [
    "## Grapheme‑Phoneme Complexity using Berndt et al. (1987)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014ce11f-802a-49ee-91f2-e2c5bbb7274c",
   "metadata": {},
   "source": [
    "### Average of Grapheme‑Phoneme Complexity by word\n",
    "\n",
    "Will calculate the following for vowels, consonants, and both vowels and consonants\n",
    "\n",
    "1. Prior probability\n",
    "2. Max probability: The max probability strength between grapheme(s) and phoneme\n",
    "3. Mid probability: The mid-range probability strength between grapheme(s) and phoneme\n",
    "4. Mean probability: The min probability strength between grapheme(s) and phonem\n",
    "5. Number of phonemes: The number of phonemes associate with a grapheme\n",
    "\n",
    "Do this for consonants (while removing vowels with consonants in them) and then for vowels and then combine the results from both of these (but do not do it for both vowels and consonants at the same time)\n",
    "\n",
    "Need to start with longer character clusters first and then remove them from the word so things are not double counted.\n",
    "\n",
    "1. Three and four character vowels (just remove them because a word like bought needs to have the ough removed initially and changed to bt)\n",
    "2. Four character phonemes\n",
    "3. Three character phonemes\n",
    "4. Two character phonemes that are exceptions (see regular expressions)\n",
    "5. Two character phonemes that are not exceptions\n",
    "6. One character phonemes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13c3aa6",
   "metadata": {},
   "source": [
    "Call in dataframes\n",
    "\n",
    "In the data frames, the columns are\n",
    "\n",
    "0 - Grapheme\n",
    "\n",
    "1 - Prior_prob\n",
    "\n",
    "2 - Max_prob\n",
    "\n",
    "3 - Min_prob\n",
    "\n",
    "4 - Mid_prob\n",
    "\n",
    "5 - Num_phonemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22efd4dc-359d-45e2-9b4a-51e120c5d966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>0.0206</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "      <td>0.0420</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.3825</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.4995</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.4995</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "      <td>0.0169</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.3240</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>H</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>J</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>K</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>L</td>\n",
       "      <td>0.0451</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>M</td>\n",
       "      <td>0.0313</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.4995</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>N</td>\n",
       "      <td>0.0710</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.4995</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>P</td>\n",
       "      <td>0.0304</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Q</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>R</td>\n",
       "      <td>0.0841</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>S</td>\n",
       "      <td>0.0488</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.4355</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>T</td>\n",
       "      <td>0.0713</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.4490</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>V</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>W</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>X</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.4490</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Z</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.4490</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0       1      2      3       4  5\n",
       "0   B  0.0206  1.000  1.000  1.0000  1\n",
       "1   C  0.0420  0.757  0.008  0.3825  3\n",
       "2   D  0.0336  0.991  0.008  0.4995  2\n",
       "3   F  0.0146  0.998  0.001  0.4995  2\n",
       "4   G  0.0169  0.640  0.008  0.3240  3\n",
       "5   H  0.0070  1.000  1.000  1.0000  1\n",
       "6   J  0.0020  1.000  1.000  1.0000  1\n",
       "7   K  0.0055  1.000  1.000  1.0000  1\n",
       "8   L  0.0451  1.000  1.000  1.0000  1\n",
       "9   M  0.0313  0.971  0.028  0.4995  2\n",
       "10  N  0.0710  0.967  0.032  0.4995  2\n",
       "11  P  0.0304  1.000  1.000  1.0000  1\n",
       "12  Q  0.0001  1.000  1.000  1.0000  1\n",
       "13  R  0.0841  1.000  1.000  1.0000  1\n",
       "14  S  0.0488  0.868  0.003  0.4355  4\n",
       "15  T  0.0713  0.973  0.003  0.4490  3\n",
       "16  V  0.0136  1.000  1.000  1.0000  1\n",
       "17  W  0.0053  1.000  1.000  1.0000  1\n",
       "18  X  0.0033  0.885  0.114  0.4490  2\n",
       "19  Z  0.0021  0.996  0.008  0.4490  3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call in dictionaries\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#call in dataframe by number of words\n",
    "berndt_1_df = pd.read_csv('cons_cond_prob_berndt_no_except_one_char.csv', na_values='', header=None)\n",
    "\n",
    "berndt_2_df = pd.read_csv('cons_cond_prob_berndt_no_except_two_char.csv', na_values='', header=None)\n",
    "\n",
    "berndt_3_df = pd.read_csv('cons_cond_prob_berndt_no_except_three_char.csv', na_values='', header=None)\n",
    "#this has following rules added\n",
    "#si as sh/zh needs to become sio (for words like passion and mansion) \n",
    "#ti as sh to tio (captures everything in nation and similar words)\n",
    "\n",
    "berndt_4_df = pd.read_csv('cons_cond_prob_berndt_no_except_four_char.csv', na_values='', header=None)\n",
    "#this has following rule added (ssi as sh/zh needs to become ssio to distinguish harnessing from possession)\n",
    "\n",
    "berndt_1_df\n",
    "#berndt_2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6ce9ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NGUE': [1e-05, 1.0, 1.0, 1.0, 1.0], 'SSIO': [0.0004, 1.0, 1.0, 1.0, 1.0]}\n",
      "B\n",
      "[0.0206, 1.0, 1.0, 1.0, 1.0]\n",
      "C\n",
      "[0.042, 0.757, 0.008, 0.3825, 3.0]\n",
      "D\n",
      "[0.0336, 0.991, 0.008, 0.4995, 2.0]\n",
      "F\n",
      "[0.0146, 0.998, 0.001, 0.4995, 2.0]\n",
      "G\n",
      "[0.0169, 0.64, 0.008, 0.324, 3.0]\n"
     ]
    }
   ],
   "source": [
    "#Start small\n",
    "\n",
    "#Convert to dictionary\n",
    "\n",
    "berndt_4_df_tran = berndt_4_df.set_index(0).transpose() #this transposes, but also makes column 0 (the words) the header\n",
    "berndt_4_df_tran =berndt_4_df_tran.to_dict('list') #makes it into a single dictionary and uses header as key and list as values\n",
    "\n",
    "\n",
    "berndt_3_df_tran = berndt_3_df.set_index(0).transpose() #this transposes, but also makes column 0 (the words) the header\n",
    "berndt_3_df_tran =berndt_3_df_tran.to_dict('list') #makes it into a single dictionary and uses header as key and list as values\n",
    "\n",
    "\n",
    "berndt_2_df_tran = berndt_2_df.set_index(0).transpose() #this transposes, but also makes column 0 (the words) the header\n",
    "berndt_2_df_tran =berndt_2_df_tran.to_dict('list') #makes it into a single dictionary and uses header as key and list as values\n",
    "\n",
    "\n",
    "berndt_1_df_tran = berndt_1_df.set_index(0).transpose() #this transposes, but also makes column 0 (the words) the header\n",
    "berndt_1_df_tran =berndt_1_df_tran.to_dict('list') #makes it into a single dictionary and uses header as key and list as values\n",
    "\n",
    "#print out key and values\n",
    "\n",
    "print(berndt_4_df_tran)\n",
    "\n",
    "#see what is in there\n",
    "counter = 0\n",
    "\n",
    "for key, val in berndt_1_df_tran.items():\n",
    "    print(key)\n",
    "    print(val)\n",
    "    counter += 1\n",
    "    if counter == 5:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a8bc73-7131-4a03-8b35-5d1c006e03b2",
   "metadata": {},
   "source": [
    "**Start here with counts for consonants**\n",
    "\n",
    "Calculate values for 3 and 4 character consonant phonemes first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4419152",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Full list of words\n",
    "#words = ['BOUGHT', 'DOUGH', 'HEIGHT', 'STRAIGHT', 'CAUGHT', 'VIEW', 'NIGHT', 'AWE', 'BROWSE', 'GARGOYLE', 'JUICE', 'SCREEN', 'MEN', 'EATEN', 'BOBBY', 'TONGUE', 'ROGUE', 'TALK', 'ALL', 'LATER', 'QUILTED', 'SOCIAL', 'FUSION', 'PASSED', 'SKETCH', 'SPECIAL', 'MISSION', 'CAPTION', 'A', 'MEDAL', 'INCONSEQUENTIAL', 'GOAL', 'WASHED', 'PACED', 'PICKED', 'GLARED', 'EASEL', 'ABLE', 'FEEL', \"EEL\", \"YES\", 'BELIEVE', 'KISSES', 'TEST', 'GIRL', 'ENGINE', 'DETAIL', 'PENCIL', 'NIMBLE', 'EVIL', 'GENTILE', 'CLEAN', 'PISTOL', 'DROOL', 'PYLON', 'GOON', 'NATION', 'CHANGES', 'BRAVES', 'TIMES', 'DROOL']\n",
    "\n",
    "#smaller list of words\n",
    "#words = ['BOUGHT',  'MEN', 'EATEN', 'TONGUE', 'AWE', 'MISSIONED', 'GOAL', 'WASHED', 'ABLE', 'KISSES', 'TIMES', 'MOM']\n",
    "\n",
    "#words from the actual CMU dict\n",
    "#words_2 = ['A', 'AS', 'A42128', 'AA', 'AAA', 'AABERG', 'AACHEN', 'AACHENER', 'AAH', 'AAKER']\n",
    "\n",
    "#set up list for cleaned words\n",
    "clean_words = []\n",
    "\n",
    "#set up list of lists to index results\n",
    "prior_prob = [[] for x in range(len(words))] #set up a list of lists that is as long as the list of words\n",
    "max_prob = [[] for x in range(len(words))] \n",
    "min_prob = [[] for x in range(len(words))] \n",
    "mid_prob = [[] for x in range(len(words))] \n",
    "number_phonemes = [[] for x in range(len(words))] \n",
    "\n",
    "\n",
    "for i, word in enumerate(words):  # iterate over the list of words, starting with word 0. For i starts count at 0 and enumerates through list\n",
    "    for key, val in berndt_4_df_tran.items(): #start with 4 character phonemes. Call in dictionary\n",
    "        while key in word: #while key in dictionary is in word (allows for counts of multiple keys as in the M in MOM)\n",
    "            #print(key) #the key to make sure it is working\n",
    "            #how the values are numbered\n",
    "            #print(val[0]) #prior_prob\n",
    "            #print(val[1]) #max_prob\n",
    "            #print(val[2]) #min_prob\n",
    "            #print(val[3]) #mid_prob\n",
    "            #print(val[4]) #num_phonemes\n",
    "            prior_prob[i].append(val[0]) #appends value to first list of lists [0] because tongue is [0] element\n",
    "            max_prob[i].append(val[1]) \n",
    "            min_prob[i].append(val[2]) \n",
    "            mid_prob[i].append(val[3]) \n",
    "            number_phonemes[i].append(val[4]) \n",
    "            word = word.replace(key, '', 1) #replace the key with empty characters. Does this one at a time though to count all incidences that may repeat (M in MOM)\n",
    "    for key, val in berndt_3_df_tran.items(): #next is 3 character phonemes\n",
    "        while key in word:\n",
    "            #print(key) #the key\n",
    "            prior_prob[i].append(val[0])\n",
    "            max_prob[i].append(val[1]) \n",
    "            min_prob[i].append(val[2]) \n",
    "            mid_prob[i].append(val[3]) \n",
    "            number_phonemes[i].append(val[4]) \n",
    "            word = word.replace(key, '', 1)\n",
    "    clean_words.append(word) #this is a check to make sure the code is removing character phonemes\n",
    "\n",
    "#print(words_2)\n",
    "#print(prior_prob)\n",
    "#print(max_prob)\n",
    "#print(min_prob)\n",
    "#print(mid_prob)\n",
    "#print(number_phonemes)\n",
    "#print(clean_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e8bdd5d-77b8-4088-95a8-5f5ff69ec083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'AS', 'A42128', 'AA', 'AAA', 'AABERG', 'AACHEN', 'AACHENER', 'AAH', 'AAKER']\n",
      "121753\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[], [], [], [], [], [], [], [], [], []]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(clean_words[:10])\n",
    "print(len(clean_words))\n",
    "prior_prob[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14979b99-e9e3-48e4-a3af-1d4db317e656",
   "metadata": {},
   "source": [
    "**Next, call in exception consonant phonemes that are all two characters long**\n",
    "\n",
    "These all happen at end of word and should not overlap with 3-4 character phonemes (see exception with special wherein 'cia' is removed leaving spel and el at the end of the word is an exception in a word like 'easel').\n",
    "\n",
    "Rules are here\n",
    "\n",
    "- al to ul at end of word as long as word is < 4 characters (medal, commercial, but not veal, goal, pal, gal)\n",
    "\n",
    "- ed as t in past tense at end preceded by voiceless consonants (picked, paced, passed, washed). This rule is not in the data, so... probably just all of them? Words should be longer than 3 so it picks up 'aced' but not 'red'\n",
    "\n",
    "- el as in l when at the end of word and not preceded by a vowel (easel but not feel)\n",
    "\n",
    "- en as un when at the end of a word and preceded by a vowel and the word is over 3 characters (so, raven and eaten, but not screen or men)\n",
    "\n",
    "- es as z when at the end of word except when sibilant (wishes, whizzes, kisses, races, prizes, watches, changes). Should be longer than 3 letters (aces but not yes)\n",
    "\n",
    "- gi as dg except at beginning of word (girl versus engine)  \n",
    "\n",
    "- il as ul at the end of the word except when preceded by a vowel (detail v pencil)\n",
    "\n",
    "- le as ul when at the end of the word and preceded by consonant (able and nimble but not gentile) \n",
    "\n",
    "- ol as ul when at the end of the word and preceded by consonant (pistol and carol but not drool) \n",
    "\n",
    "- on as un when at the end of the word and preceded by consonant (pylon and iron but not goon or nation) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707049e6-6562-497c-927b-68d59069d13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "these are the words to remove later [[], [], [], ['EATEN'], [], [], ['MINED'], [], ['WASHED'], ['ABLE'], [], ['TIMES'], []]\n",
      "these are what remains of the words above to add back to the original list of words after the complete words have been removed ['EAT', 'MIN', 'WASH', 'AB', 'TIM']\n",
      "[[], [], [], [7e-05], [1e-05], [], [0.0004, 0.0002], [], [0.0002], [0.0057], [], [0.0004], []]\n",
      "[[], [], [], [1.0], [1.0], [], [1.0, 1], [], [1], [1], [], [1], []]\n",
      "[[], [], [], [1.0], [1.0], [], [1.0, 1], [], [1], [1], [], [1], []]\n",
      "[[], [], [], [1.0], [1.0], [], [1.0, 1], [], [1], [1], [], [1], []]\n",
      "[[], [], [], [1.0], [1.0], [], [1.0, 1], [], [1], [1], [], [1], []]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "#print(clean_words)\n",
    "\n",
    "al_dict = {'AL': [.00003, 1.0, 1.0, 1.0, 1.0]}\n",
    "ed_dict = {'ED': [0.0002, 1, 1, 1, 1]}\n",
    "el_dict = {'EL': [0.0001, 1, 1, 1, 1]}\n",
    "en_dict = {'EN': [.00007, 1.0, 1.0, 1.0, 1.0]}\n",
    "es_dict = {'ES': [0.0004, 1, 1, 1, 1]}\n",
    "gi_dict = {'GI': [0.0001, 1, 1, 1, 1]}\n",
    "il_dict = {'IL': [0.00006, 1, 1, 1, 1]}\n",
    "le_dict = {'LE': [0.0057, 1, 1, 1, 1]}\n",
    "ol_dict = {'OL': [0.000009, 1, 1, 1, 1]}\n",
    "on_dict = {'ON': [0.00002, 1, 1, 1, 1]}\n",
    "qu_dict = {'QU': [0.002, 0.876, 0.123, 0.4995, 2]}\n",
    "ti_dict = {'TI': [0.0076, 0.983, 0.001, 0.449, 3]}\n",
    "\n",
    "except_words_2 = [] #list of words that need to be removed from the words_2 before the next stage of cleaning\n",
    "clean_words_2 = [] #this is a list of partial words that need to be moved back into clean_words\n",
    "\n",
    "for i, word in enumerate(clean_words):  # iterate over the list of words, starting with word 0. For i starts count at 0 and enumerates through list\n",
    "    except_words = [] #holder list of words to remove\n",
    "    # for words that end in al and are over 4 letters long\n",
    "    if len(word) > 4: #if word longer than 4 characters\n",
    "        if re.match(r'.*AL$', word): #if word ends in AL\n",
    "            #print(word)\n",
    "            except_words.append(word) #put the word in the exception list\n",
    "            for word in except_words:\n",
    "                #print(word)\n",
    "                #need to remove word from words_2 now. Later, will need to put clean_words back into words_2\n",
    "                for key, val in al_dict.items(): #call in dictionary\n",
    "                    #print(key)\n",
    "                    while key in word: #if key is in word (i.e., does word include 'al', append information\n",
    "                        #print(key)\n",
    "                        prior_prob[i].append(val[0])\n",
    "                        max_prob[i].append(val[1]) \n",
    "                        min_prob[i].append(val[2]) \n",
    "                        mid_prob[i].append(val[3]) \n",
    "                        number_phonemes[i].append(val[4]) \n",
    "                        word = word.replace(key, '', 1) #replace the key in the word with nothing (i.e., 'medal' becomes 'med')\n",
    "                clean_words_2.append(word) #this is to keep list of remaining characters in words to return to larger list of words later\n",
    "            #print(except_words)\n",
    "    except_words_2.append(except_words) #move except words into larger list (CHECK THIS. YOU ONLY CALL IT ONCE!!!!)\n",
    "    # for words that end in ed\n",
    "    if len(word) > 3: #if word longer than 3\n",
    "        if re.match(r'.*ED$', word): #if it ends in ED\n",
    "            #print(word)\n",
    "            except_words.append(word)\n",
    "            for word in except_words:\n",
    "                for key, val in ed_dict.items():\n",
    "                    while key in word:\n",
    "                        #print(key)\n",
    "                        prior_prob[i].append(val[0])\n",
    "                        max_prob[i].append(val[1]) \n",
    "                        min_prob[i].append(val[2]) \n",
    "                        mid_prob[i].append(val[3]) \n",
    "                        number_phonemes[i].append(val[4]) \n",
    "                        word = word.replace(key, '', 1)\n",
    "                clean_words_2.append(word) \n",
    "    if re.match(r'.+[^AEIOU]EL$', word):\n",
    "        #print(word)\n",
    "        except_words.append(word)\n",
    "        for word in except_words:\n",
    "            for key, val in el_dict.items():\n",
    "                while key in word:\n",
    "                    #print(key)\n",
    "                    prior_prob[i].append(val[0])\n",
    "                    max_prob[i].append(val[1]) \n",
    "                    min_prob[i].append(val[2]) \n",
    "                    mid_prob[i].append(val[3]) \n",
    "                    number_phonemes[i].append(val[4]) \n",
    "                    word = word.replace(key, '', 1)\n",
    "            clean_words_2.append(word) \n",
    "    if len(word) > 3: #if word longer than 3\n",
    "        if re.match(r'.+[^AEIOU]EN$', word): #if it ends in EN\n",
    "            #print(word)\n",
    "            except_words.append(word)\n",
    "            for word in except_words:\n",
    "                for key, val in en_dict.items():\n",
    "                    while key in word:\n",
    "                        #print(key)\n",
    "                        prior_prob[i].append(val[0])\n",
    "                        max_prob[i].append(val[1]) \n",
    "                        min_prob[i].append(val[2]) \n",
    "                        mid_prob[i].append(val[3]) \n",
    "                        number_phonemes[i].append(val[4]) \n",
    "                        word = word.replace(key, '', 1)\n",
    "                clean_words_2.append(word) \n",
    "    if re.match(r'.+[^(?:SS|Z|CH|G|C)]ES$', word): #if words ends in ES and has sibilant before it\n",
    "        #print(word)\n",
    "        except_words.append(word)\n",
    "        for word in except_words:\n",
    "            for key, val in es_dict.items():\n",
    "                while key in word:\n",
    "                    #print(key)\n",
    "                    prior_prob[i].append(val[0])\n",
    "                    max_prob[i].append(val[1]) \n",
    "                    min_prob[i].append(val[2]) \n",
    "                    mid_prob[i].append(val[3]) \n",
    "                    number_phonemes[i].append(val[4]) \n",
    "                    word = word.replace(key, '', 1)\n",
    "            clean_words_2.append(word)\n",
    "    if re.match(r'(?!GI)\\w*GI\\w*(?<!GI)', word): #if words contains GI, except at the beginning\n",
    "        #print(word)\n",
    "        except_words.append(word)\n",
    "        for word in except_words:\n",
    "            for key, val in gi_dict.items():\n",
    "                while key in word:\n",
    "                    #print(key)\n",
    "                    prior_prob[i].append(val[0])\n",
    "                    max_prob[i].append(val[1]) \n",
    "                    min_prob[i].append(val[2]) \n",
    "                    mid_prob[i].append(val[3]) \n",
    "                    number_phonemes[i].append(val[4]) \n",
    "                    word = word.replace(key, '', 1)\n",
    "            clean_words_2.append(word)\n",
    "    if re.match(r'.+[^AEIOU]IL$', word): #if word ends in IL\n",
    "        #print(word)\n",
    "        except_words.append(word)\n",
    "        for word in except_words:\n",
    "            for key, val in il_dict.items():\n",
    "                while key in word:\n",
    "                    #print(key)\n",
    "                    prior_prob[i].append(val[0])\n",
    "                    max_prob[i].append(val[1]) \n",
    "                    min_prob[i].append(val[2]) \n",
    "                    mid_prob[i].append(val[3]) \n",
    "                    number_phonemes[i].append(val[4]) \n",
    "                    word = word.replace(key, '', 1)\n",
    "            clean_words_2.append(word)\n",
    "    if re.match(r'.+[^AEIOU]LE$', word): #if word ends in LE\n",
    "        #print(word)\n",
    "        except_words.append(word)\n",
    "        for word in except_words:\n",
    "            for key, val in le_dict.items():\n",
    "                while key in word:\n",
    "                    #print(key)\n",
    "                    prior_prob[i].append(val[0])\n",
    "                    max_prob[i].append(val[1]) \n",
    "                    min_prob[i].append(val[2]) \n",
    "                    mid_prob[i].append(val[3]) \n",
    "                    number_phonemes[i].append(val[4]) \n",
    "                    word = word.replace(key, '', 1)\n",
    "            clean_words_2.append(word)\n",
    "    if re.match(r'.+[^AEIOU]OL$', word): #if words ends in OL\n",
    "        #print(word)\n",
    "        except_words.append(word)\n",
    "        for word in except_words:\n",
    "            for key, val in ol_dict.items():\n",
    "                while key in word:\n",
    "                    #print(key)\n",
    "                    prior_prob[i].append(val[0])\n",
    "                    max_prob[i].append(val[1]) \n",
    "                    min_prob[i].append(val[2]) \n",
    "                    mid_prob[i].append(val[3]) \n",
    "                    number_phonemes[i].append(val[4]) \n",
    "                    word = word.replace(key, '', 1)\n",
    "            clean_words_2.append(word) \n",
    "    if re.match(r'.+[^AEIOU]ON$', word): #if word ends in ON\n",
    "        #print(word)\n",
    "        except_words.append(word)\n",
    "        for word in except_words:\n",
    "            for key, val in on_dict.items():\n",
    "                while key in word:\n",
    "                    #print(key)\n",
    "                    prior_prob[i].append(val[0])\n",
    "                    max_prob[i].append(val[1]) \n",
    "                    min_prob[i].append(val[2]) \n",
    "                    mid_prob[i].append(val[3]) \n",
    "                    number_phonemes[i].append(val[4]) \n",
    "                    word = word.replace(key, '', 1)\n",
    "            clean_words_2.append(word) \n",
    "            \n",
    "#print(f'these are the words to remove later {except_words_2}')                      \n",
    "#print(f'these are what remains of the words above to add back to the original list of words after the complete words have been removed {clean_words_2}')\n",
    "#print(prior_prob)\n",
    "#print(max_prob)\n",
    "#print(min_prob)\n",
    "#print(mid_prob)\n",
    "#print(number_phonemes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b590f104-6b69-444c-af5c-8f8143eb39dd",
   "metadata": {},
   "source": [
    "**Replace existing word list with shortened words as a result of above for VOWEL COUNTS later**\n",
    "\n",
    "This will give us a list of the remaining words in which 3-4 character phonemes have been removed along with 2 character exception phonemes.\n",
    "\n",
    "This list will be used for vowel probabilities.\n",
    "\n",
    "We will continue with extracting consonants and then move to vowels. But vowel rules require that the the words are mostly natural except for the removal of exceptions.\n",
    "\n",
    "So, for instance, the word TONGUE needs to be shortened to TO or the vowel counts will be calculated on the UE at the end of the word (even thought that UE is part of NGUE, which is a consonant).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0251be7-8e4b-4fc5-9304-bd10e7217bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f'these are the original words {words}\\n') #the original list\n",
    "\n",
    "#print(f'these are the original words after first pass for 3-4 character phonemes {clean_words}\\n') #the original list\n",
    "\n",
    "words_to_remove = []\n",
    "for sublist in except_words_2:\n",
    "    for word in sublist:\n",
    "        words_to_remove.append(word)\n",
    "\n",
    "#print(f'These are the words with exceptions that were processed and need to be removed {words_to_remove}\\n') #note, special is a hard one... cia is removed [sh]\n",
    "# leaving spel, which ends in an 'el'\n",
    "\n",
    "#print(f'these are the parts of the exception words left over after processing {clean_words_2}\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7695e40-fb22-4a86-9a62-c7cdb9f489ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now, we need a list to next set of consonants and to extract vowel probabilities in the near future\n",
    "#1. take the original words\n",
    "#2. remove the exception words that were processed\n",
    "#3. replace those words with their remaining parts after processing in the same order\n",
    "\n",
    "\n",
    "# create a new list that will store the updated list_1\n",
    "clean_words_vowels = []\n",
    "\n",
    "# loop through the words in the original list\n",
    "for word in clean_words:\n",
    "    #print(word)\n",
    "    # if the word was processed as an exception, replace it with the corresponding set of characters that remain after processing\n",
    "    if word in words_to_remove:\n",
    "        #print(word)\n",
    "        clean_words_vowels.append(clean_words_2[words_to_remove.index(word)])#index returns the position at the first occurrence of the specified value\n",
    "    # if the word is not in words_to_remove, add it to the processed_list_for_vowel_extraction list\n",
    "    else:\n",
    "        clean_words_vowels.append(word)\n",
    "\n",
    "# print the final list for vowel probability extraction\n",
    "#print(f'this was the original list of words {words_2}\\n')\n",
    "#print(f'this is the list for vowel extraction and next steps in consonants {clean_words_vowels}') #Think this is right except for special, which should be spel, but is sp\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c4e29b-7547-41bd-85e8-9a7d8fab0b09",
   "metadata": {},
   "source": [
    "**Next, call in 1 and 2 character phonemes (consonants)**\n",
    "\n",
    "***HERE WE CONTINUE WITH THE CONSONANT COUNTS***\n",
    "\n",
    "Run counts for 1 and 2 consonant character phonemes on the remaining characters\n",
    "\n",
    "NOTE that the output will be useless for counting vowel probabilities\n",
    "\n",
    "['E', '', 'OY', 'O', 'O', 'A', 'A', 'AE', 'O', 'U', 'E', 'I', 'AIO', 'A', 'OA', 'EE', 'EE', 'YE', 'EIEE', 'IE', 'E', 'I', 'EAI', 'IE', 'EA', 'OO', 'OO', 'AIO', 'AE', 'OO', 'EA', 'UI', 'A', '', 'E', 'IOEUI', 'A', 'A', 'I', 'A', 'EA', 'A', 'E', '', 'I', 'E', 'I', 'Y', 'A', 'I']\n",
    "\n",
    "Because we do not know where the vowels are broken up by consonants. Hence, we have to use the words after exception consonants removed (i.e, clean_words_3).\n",
    "\n",
    "Also, we first remove vowels that contain consonants (e.g., AIGH in STRAIGHT) so they are not counted twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a3bd70-1f8a-4bbe-bc0c-50512c801cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f'this was the original list of words {words}\\n')\n",
    "#print(f'this is the list of words for final consonant cleaning with 2 and 1 character consonant phonemes {clean_words_vowels}\\n')\n",
    "\n",
    "\n",
    "vowels_to_remove = ['AIGH', 'AUGH', 'EIGH', 'OUGH', 'IGH', 'IEW'] #these are long vowels that contain consonants. Need to remove them so the consonants are not counted (e.g., STRAIGHT, VIEW)\n",
    "\n",
    "clean_words_3 = []\n",
    "\n",
    "for word in clean_words_vowels:\n",
    "    for vowel in vowels_to_remove:\n",
    "        if vowel in word:\n",
    "            word = word.replace(vowel, '_') #replace the key with _ that represents a vowel. If you replace with nothing, for the word BOUGHT you get BT, which is a consonant with two phonemes\n",
    "    clean_words_3.append(word)\n",
    "\n",
    "#print(f'this is the list of words with vowels containing consonants removed{clean_words_3}')\n",
    "\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967d617a-4ebd-44f3-97ea-0cc4180af89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this was the original list of words ['LAUGH', 'BOUGHT', 'MEN', 'EATEN', 'TONGUE', 'AWE', 'MISSIONED', 'GOAL', 'WASHED', 'ABLE', 'KISSES', 'TIMES', 'MOM']\n",
      "\n",
      "this is the list of words for final consonant cleaning with 2 and 1 character consonant phonemes ['L_', 'B_T', 'MEN', 'EAT', 'TO', 'AWE', 'MIN', 'GOAL', 'WASH', 'AB', 'KISSES', 'TIM', 'MOM']\n",
      "\n",
      "[[0.0451, 0.0451], [0.0206, 0.0713, 0.0206, 0.0713], [0.0313, 0.071, 0.0313, 0.071], [7e-05, 0.0713, 0.0713], [1e-05, 0.0713, 0.0713], [0.0053, 0.0053], [0.0004, 0.0002, 0.0313, 0.071, 0.0313, 0.071], [0.0169, 0.0451, 0.0169, 0.0451], [0.0002, 0.0036, 0.0053, 0.0036, 0.0053], [0.0057, 0.0206, 0.0206], [0.0042, 0.0055, 0.0488, 0.0042, 0.0055, 0.0488], [0.0004, 0.0313, 0.0713, 0.0313, 0.0713], [0.0313, 0.0313, 0.0313, 0.0313]]\n",
      "[[1.0, 1.0], [1.0, 0.973, 1.0, 0.973], [0.971, 0.967, 0.971, 0.967], [1.0, 0.973, 0.973], [1.0, 0.973, 0.973], [1.0, 1.0], [1.0, 1, 0.971, 0.967, 0.971, 0.967], [0.64, 1.0, 0.64, 1.0], [1, 1.0, 1.0, 1.0, 1.0], [1, 1.0, 1.0], [0.952, 1.0, 0.868, 0.952, 1.0, 0.868], [1, 0.971, 0.973, 0.971, 0.973], [0.971, 0.971, 0.971, 0.971]]\n",
      "[[1.0, 1.0], [1.0, 0.003, 1.0, 0.003], [0.028, 0.032, 0.028, 0.032], [1.0, 0.003, 0.003], [1.0, 0.003, 0.003], [1.0, 1.0], [1.0, 1, 0.028, 0.032, 0.028, 0.032], [0.008, 1.0, 0.008, 1.0], [1, 1.0, 1.0, 1.0, 1.0], [1, 1.0, 1.0], [0.019, 1.0, 0.003, 0.019, 1.0, 0.003], [1, 0.028, 0.003, 0.028, 0.003], [0.028, 0.028, 0.028, 0.028]]\n",
      "[[1.0, 1.0], [1.0, 0.449, 1.0, 0.449], [0.4995, 0.4995, 0.4995, 0.4995], [1.0, 0.449, 0.449], [1.0, 0.449, 0.449], [1.0, 1.0], [1.0, 1, 0.4995, 0.4995, 0.4995, 0.4995], [0.324, 1.0, 0.324, 1.0], [1, 1.0, 1.0, 1.0, 1.0], [1, 1.0, 1.0], [0.4855, 1.0, 0.4355, 0.4855, 1.0, 0.4355], [1, 0.4995, 0.449, 0.4995, 0.449], [0.4995, 0.4995, 0.4995, 0.4995]]\n",
      "[[1.0, 1.0], [1.0, 3.0, 1.0, 3.0], [2.0, 2.0, 2.0, 2.0], [1.0, 3.0, 3.0], [1.0, 3.0, 3.0], [1.0, 1.0], [1.0, 1, 2.0, 2.0, 2.0, 2.0], [3.0, 1.0, 3.0, 1.0], [1, 1.0, 1.0, 1.0, 1.0], [1, 1.0, 1.0], [3.0, 1.0, 4.0, 3.0, 1.0, 4.0], [1, 2.0, 3.0, 2.0, 3.0], [2.0, 2.0, 2.0, 2.0]]\n",
      "this is what is left of the words with all the consonants counted ['_', '_', 'E', 'EA', 'O', 'AE', 'I', 'OA', 'A', 'A', 'IE', 'I', 'O']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clean_words_4 = []\n",
    "\n",
    "for i, word in enumerate(clean_words_3):  # iterate over the list of words, starting with word 0. For i starts count at 0 and enumerates through list\n",
    "    for key, val in berndt_2_df_tran.items(): #next is 2 character phonemes\n",
    "        while key in word:\n",
    "            #print(key) #the key\n",
    "            prior_prob[i].append(val[0])\n",
    "            max_prob[i].append(val[1]) \n",
    "            min_prob[i].append(val[2]) \n",
    "            mid_prob[i].append(val[3]) \n",
    "            number_phonemes[i].append(val[4]) \n",
    "            word = word.replace(key, '', 1)\n",
    "    for key, val in berndt_1_df_tran.items(): #next is 1 character phonemes\n",
    "        while key in word:\n",
    "            #print(key) #the key\n",
    "            prior_prob[i].append(val[0])\n",
    "            max_prob[i].append(val[1]) \n",
    "            min_prob[i].append(val[2]) \n",
    "            mid_prob[i].append(val[3]) \n",
    "            number_phonemes[i].append(val[4]) \n",
    "            word = word.replace(key, '', 1)\n",
    "    clean_words_4.append(word) #this is a check to make sure the code is removing character phonemes\n",
    "\n",
    "#print(f'this was the original list of words {words_2}\\n')\n",
    "#print(f'this is the list of words for final consonant cleaning with 2 and 1 character consonant phonemes {clean_words_3}\\n')\n",
    "#print(prior_prob)\n",
    "#print(max_prob)\n",
    "#print(min_prob)\n",
    "#print(mid_prob)\n",
    "#print(number_phonemes)\n",
    "#print(f'this is what is left of the words with all the consonants counted {clean_words_4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad44991-3cd4-4a23-ac41-d06cda03f62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(words[:10])\n",
    "print(prior_prob[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058bceaa-97bb-4cd2-a19f-67cf04628cd8",
   "metadata": {},
   "source": [
    "This is what we had after the exceptions and 3 and 4 character consonant phonemes\n",
    "\n",
    "[[], [], [7e-05], [1e-05], [], [0.0004, 0.0002], [], [0.0002], [0.0057], [], [0.0004]]\n",
    "[[], [], [1.0], [1.0], [], [1.0, 1], [], [1], [1], [], [1]]\n",
    "[[], [], [1.0], [1.0], [], [1.0, 1], [], [1], [1], [], [1]]\n",
    "[[], [], [1.0], [1.0], [], [1.0, 1], [], [1], [1], [], [1]]\n",
    "[[], [], [1.0], [1.0], [], [1.0, 1], [], [1], [1], [], [1]]\n",
    "\n",
    "So, it is looking good"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3832045-9860-4008-b768-181249b43498",
   "metadata": {},
   "source": [
    "Need to average by list. \n",
    "If list is empty, need to assign value of 0 to list\n",
    "Then, need to move list to pandas df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64ab900-802f-4192-a0fb-99cca57215c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for item in prior_prob:\n",
    "     if len(item)==0:\n",
    "        #print(item)\n",
    "        item.append(0)\n",
    "\n",
    "for item in max_prob:\n",
    "     if len(item)==0:\n",
    "        item.append(0)\n",
    "        \n",
    "for item in min_prob:\n",
    "     if len(item)==0:\n",
    "        item.append(0)\n",
    "\n",
    "        \n",
    "for item in mid_prob:\n",
    "     if len(item)==0:\n",
    "        item.append(0)\n",
    "\n",
    "        \n",
    "for item in number_phonemes:\n",
    "     if len(item)==0:\n",
    "        item.append(0)\n",
    "\n",
    "#print(prior_prob)\n",
    "#print(max_prob)\n",
    "#print(min_prob)\n",
    "#print(mid_prob)\n",
    "#print(number_phonemes)\n",
    "\n",
    "prior_prob_avg = [sum(sub_list) / len(sub_list) for sub_list in prior_prob]\n",
    "max_prob_avg = [sum(sub_list) / len(sub_list) for sub_list in max_prob]\n",
    "min_prob_avg = [sum(sub_list) / len(sub_list) for sub_list in min_prob]\n",
    "mid_prob_avg = [sum(sub_list) / len(sub_list) for sub_list in mid_prob]\n",
    "number_phonemes_avg = [sum(sub_list) / len(sub_list) for sub_list in number_phonemes]\n",
    "\n",
    "#print(prior_prob_avg)\n",
    "#print(max_prob_avg)\n",
    "#print(min_prob_avg)\n",
    "#print(mid_prob_avg)\n",
    "#print(number_phonemes_avg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70e7617-8a2b-404b-9aa6-132ce2b266c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prior_prob_avg[:10])\n",
    "print(max_prob_avg[:10])\n",
    "print(min_prob_avg[:10])\n",
    "print(mid_prob_avg[:10])\n",
    "print(number_phonemes_avg[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b736be68-c4d7-4137-864f-bddf8b38dd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "decoding_df['prior_prob_cons'] = prior_prob_avg #add to dataframe\n",
    "decoding_df['max_prob_cons'] = max_prob_avg #add to dataframe\n",
    "decoding_df['min_prob_cons'] = min_prob_avg #add to dataframe\n",
    "decoding_df['mid_prob_cons'] = mid_prob_avg #add to dataframe\n",
    "decoding_df['number_phonemes_cons'] = number_phonemes_avg #add to dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e809b919-2b2d-4cc5-82e5-c0fe14ac9237",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoding_df[25000:25010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3286c823-a21c-4674-8722-8fefc897ea54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to a .csv for later use if needed\n",
    "\n",
    "decoding_df.to_csv(\"everything_except_vowel_prob.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d5b779-0714-4c9f-84a3-1ca75a074d06",
   "metadata": {},
   "source": [
    "**Start here with counts for vowels**\n",
    "\n",
    "Calculate values for 3 and 4 character vowel phonemes first.\n",
    "\n",
    "Start all over with the word list after consonant exceptions. This will have the meaningful vowels left in it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5791673d-de59-4530-bf98-4f94c5b9638d",
   "metadata": {},
   "source": [
    "First, call in dataframes with conditional probabilities for vowels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49213693-5837-4b62-8c4c-501bb1af7f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EAU</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.4995</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EOU</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IGH</td>\n",
       "      <td>0.00080</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lEU</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lEW</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0        1      2      3       4  5\n",
       "0  EAU  0.00010  0.545  0.454  0.4995  2\n",
       "1  EOU  0.00007  1.000  1.000  1.0000  1\n",
       "2  IGH  0.00080  1.000  1.000  1.0000  1\n",
       "3  lEU  0.00003  1.000  1.000  1.0000  1\n",
       "4  lEW  0.00003  1.000  1.000  1.0000  1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#call in dataframe by number of words\n",
    "berndt_1_vow_df = pd.read_csv('vow_cond_prob_berndt_no_except_one_char.csv', na_values='', header=None)\n",
    "\n",
    "berndt_2_vow_df = pd.read_csv('vow_cond_prob_berndt_no_except_two_char.csv', na_values='', header=None)\n",
    "\n",
    "berndt_3_vow_df = pd.read_csv('vow_cond_prob_berndt_no_except_three_char.csv', na_values='', header=None)\n",
    "\n",
    "berndt_4_vow_df = pd.read_csv('vow_cond_prob_berndt_no_except_four_char.csv', na_values='', header=None)\n",
    "\n",
    "berndt_3_vow_df\n",
    "#berndt_2_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f91f29-2e20-4742-9a9f-bea7c0e7dbcf",
   "metadata": {},
   "source": [
    "Turn these dataframes into useable dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82d3ec32-dadb-4d07-9d22-b1460f4de780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AIGH': [3e-05, 1.0, 1.0, 1.0, 1.0], 'AUGH': [0.0001, 1.0, 1.0, 1.0, 1.0], 'EIGH': [0.0001, 0.857, 0.142, 0.4995, 2.0], 'OUGH': [0.0002, 0.517, 0.068, 0.2925, 4.0]}\n",
      "{'EAU': [0.0001, 0.545, 0.454, 0.4995, 2.0], 'EOU': [7e-05, 1.0, 1.0, 1.0, 1.0], 'IGH': [0.0008, 1.0, 1.0, 1.0, 1.0], 'lEU': [3e-05, 1.0, 1.0, 1.0, 1.0], 'lEW': [3e-05, 1.0, 1.0, 1.0, 1.0]}\n"
     ]
    }
   ],
   "source": [
    "#Convert to dictionary\n",
    "\n",
    "berndt_4_vow_df_tran = berndt_4_vow_df.set_index(0).transpose() #this transposes, but also makes column 0 (the words) the header\n",
    "berndt_4_vow_df_tran =berndt_4_vow_df_tran.to_dict('list') #makes it into a single dictionary and uses header as key and list as values\n",
    "\n",
    "\n",
    "berndt_3_vow_df_tran = berndt_3_vow_df.set_index(0).transpose() #this transposes, but also makes column 0 (the words) the header\n",
    "berndt_3_vow_df_tran =berndt_3_vow_df_tran.to_dict('list') #makes it into a single dictionary and uses header as key and list as values\n",
    "\n",
    "\n",
    "berndt_2_vow_df_tran = berndt_2_vow_df.set_index(0).transpose() #this transposes, but also makes column 0 (the words) the header\n",
    "berndt_2_vow_df_tran =berndt_2_vow_df_tran.to_dict('list') #makes it into a single dictionary and uses header as key and list as values\n",
    "\n",
    "\n",
    "berndt_1_vow_df_tran = berndt_1_vow_df.set_index(0).transpose() #this transposes, but also makes column 0 (the words) the header\n",
    "berndt_1_vow_df_tran =berndt_1_vow_df_tran.to_dict('list') #makes it into a single dictionary and uses header as key and list as values\n",
    "\n",
    "#print out key and values\n",
    "\n",
    "#print(berndt_4_vow_df_tran)\n",
    "#print(berndt_3_vow_df_tran)\n",
    "\n",
    "#see what is in there\n",
    "counter = 0\n",
    "\n",
    "#for key, val in berndt_1_vow_df_tran.items():\n",
    "#    print(key)\n",
    "#    print(val)\n",
    "#    counter += 1\n",
    "#    if counter == 5:\n",
    "#        break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46505756-87d3-4bf3-b429-5b864cd18cd6",
   "metadata": {},
   "source": [
    "**Next set up new probability counts for vowels**\n",
    "\n",
    "These will be added to the consontant counts later to compute the following\n",
    "\n",
    "1. Probability counts all\n",
    "2. Probability counts vowels\n",
    "3. Probability counts consonants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a52a980-f026-408d-bf6d-0c2069ce3228",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f'this is the list for vowel extraction {clean_words_vowels}') #Think this is right except for special, which should be spel, but is sp. \n",
    "#Gargoyle also went to gargoy (because le is meaningful), but this seems fine.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b48aecc-a830-45db-96b8-eee3c577273a",
   "metadata": {},
   "source": [
    "**Start with 3-4 character exception vowels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e42f3d9-a640-4eba-87e6-6e1ffd422641",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clean_words_vowels)\n",
    "print(clean_words_vowels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceeda79a-e5a4-41e1-be88-53465890c1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0001], [], [], [], [], [], [], [], [], [], [], [0.0001], [], [0.0001]]\n",
      "[[1.0], [], [], [], [], [], [], [], [], [], [], [0.857], [], [1.0]]\n",
      "[[1.0], [], [], [], [], [], [], [], [], [], [], [0.142], [], [1.0]]\n",
      "[[1.0], [], [], [], [], [], [], [], [], [], [], [0.4995], [], [1.0]]\n",
      "[[1.0], [], [], [], [], [], [], [], [], [], [], [2.0], [], [1.0]]\n",
      "['L', 'CASTLE', 'SHOPPE', 'SHOVE', 'TO', 'OYE', 'AWE', 'HATE', 'HEARSE', 'PROTRUDE', 'PROTOTYPE', 'COUNTERWT', 'COYOTE', 'GT']\n"
     ]
    }
   ],
   "source": [
    "#THIS IS WHAT WE SHOULD USE (the list below clean_words_vowels)\n",
    "#print(f'this is the list for vowel extraction {clean_words_vowels}') #Think this is right except for special, which should be spel, but is sp. \n",
    "\n",
    "#BUT, SET UP CODE WITH THIS FOLLOWING LIST to test outcomes on more vowels\n",
    "\n",
    "#clean_words_vowels_prac = ['DEVALUATE', 'CASTLE', 'SHOPPE', 'SHOVE', 'TO', 'OYE', 'AWE', 'HATE', 'HEARSE', 'PROTRUDE', 'PROTOTYPE', 'COUNTERWEIGHT', 'COYOTE', 'EQUATE']\n",
    "#print(clean_words_vowels_prac)\n",
    "\n",
    "#set up count lists\n",
    "clean_words_vow = []\n",
    "\n",
    "#set up list of lists to index vowel results\n",
    "prior_prob_vow = [[] for x in range(len(clean_words_vowels))] #set up a list of lists that is as long as the list of words\n",
    "max_prob_vow = [[] for x in range(len(clean_words_vowels))] \n",
    "min_prob_vow = [[] for x in range(len(clean_words_vowels))] \n",
    "mid_prob_vow = [[] for x in range(len(clean_words_vowels))] \n",
    "number_phonemes_vow = [[] for x in range(len(clean_words_vowels))] \n",
    "\n",
    "\n",
    "for i, word in enumerate(clean_words_vowels):  # iterate over the list of words, starting with word 0. For i starts count at 0 and enumerates through list\n",
    "    for key, val in berndt_4_vow_df_tran.items(): #start with 4 character phonemes. Call in dictionary\n",
    "        while key in word: #while key in dictionary is in word. This allows for multiple keys (i.e., the EA in MEATHEAD will be counted twice)\n",
    "            #print(key) #the key to make sure it is working\n",
    "            #how the values are numbered\n",
    "            #print(val[0]) #prior_prob\n",
    "            #print(val[1]) #max_prob\n",
    "            #print(val[2]) #min_prob\n",
    "            #print(val[3]) #mid_prob\n",
    "            #print(val[4]) #num_phonemes\n",
    "            prior_prob_vow[i].append(val[0])\n",
    "            max_prob_vow[i].append(val[1]) \n",
    "            min_prob_vow[i].append(val[2]) \n",
    "            mid_prob_vow[i].append(val[3]) \n",
    "            number_phonemes_vow[i].append(val[4]) \n",
    "            word = word.replace(key, '', 1) #replace the key with empty characters, but replace only one occurrence at a time. Will ensure each item counted and put into respective lists.\n",
    "    for key, val in berndt_3_vow_df_tran.items(): #next is 3 character phonemes\n",
    "        while key in word:\n",
    "            #print(key) #the key\n",
    "            prior_prob_vow[i].append(val[0])\n",
    "            max_prob_vow[i].append(val[1]) \n",
    "            min_prob_vow[i].append(val[2]) \n",
    "            mid_prob_vow[i].append(val[3]) \n",
    "            number_phonemes_vow[i].append(val[4]) \n",
    "            word = word.replace(key, '', 1)\n",
    "\n",
    "    clean_words_vow.append(word) #this is a check to make sure the code is removing character phonemes\n",
    "\n",
    "#print(prior_prob_vow)\n",
    "#print(max_prob_vow)\n",
    "#print(min_prob_vow)\n",
    "#print(mid_prob_vow)\n",
    "#print(number_phonemes_vow)\n",
    "#print(clean_words_vow)\n",
    "\n",
    "#seems to work fine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7512502-1a22-4b98-8f3e-dddad421c102",
   "metadata": {},
   "source": [
    "**Then move onto 2 and 1 character exception vowels**\n",
    "\n",
    "Okay, now need to move to regex to remove vowels that are\n",
    "\n",
    "AI-E\n",
    "AU-E\n",
    "AW-E\n",
    "\n",
    "and\n",
    "\n",
    "A-E\n",
    "E-E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5c68e1-4434-4290-aac6-4332d66a933e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "ai_dict = {'AI': [0.0002, 0.818, 0.045, 0.4315, 3]}\n",
    "au_dict = {'AU': [0.0001, 0.75, 0.083, 0.4165, 3]}\n",
    "aw_dict = {'AW': [0.00001, 1, 1, 1, 1]}\n",
    "ay_dict = {'AY': [0.000009, 1, 1, 1, 1]}\n",
    "ea_dict = {'EA': [.00003, 1.0, 1.0, 1.0, 1.0]} #for HEARSE\n",
    "ee_dict = {'EE': [0.00008, 1, 1, 1, 1]}\n",
    "ei_dict = {'EI': [.00007, 0.75, 0.25, 0.5, 2]}\n",
    "eu_dict = {'EU': [0.000009, 1, 1, 1, 1]}\n",
    "ew_dict = {'EW': [0.000009, 1, 1, 1, 1]}\n",
    "ey_dict = {'EY': [0.00006, 1, 1, 1, 1]}\n",
    "ia_dict = {'IA': [0.00002, 1, 1, 1, 1]}\n",
    "ie_dict = {'IE': [0.0002, 0.838, 0.032, 0.435, 3]}\n",
    "oa_dict = {'OA': [0.00002, 1, 1, 1, 1]}\n",
    "oi_dict = {'OI': [0.00009, 0.8, 0.2, 0.5, 2]}\n",
    "oo_dict = {'OO': [0.0001, 1, 1, 1, 1]}\n",
    "ou_dict = {'OU': [0.0006, 0.794, 0.014, 0.404, 4]}\n",
    "ow_dict = {'OW': [0.00002, 0.666, 0.333, 0.4995, 2]}\n",
    "oy_dict = {'OY': [0.000009, 1, 1, 1, 1]}\n",
    "ui_dict = {'UI': [0.00003, 1, 1, 1, 1]}\n",
    "\n",
    "\n",
    "a_dict = {'A': [0.0111, 0.651, 0.002, 0.3265, 7]} #for AWE\n",
    "e_dict = {'E': [0.0032, 0.321, 0.002, 0.1615, 6]}\n",
    "i_dict = {'I': [0.0086, 0.589, 0.001, 0.295, 5]}\n",
    "o_dict = {'O': [0.0043, 0.785, 0.002, 0.3935, 7]}\n",
    "u_dict = {'U': [0.0033, 0.703, 0.008, 0.3555, 7]} #for RUDE\n",
    "y_dict = {'Y': [0.0002, 0.958, 0.041, 0.4995, 2]} #for TYPE\n",
    "\n",
    "\n",
    "#words_prac = ['BT', 'MEN', 'EAT', 'TO', 'AWE', 'MIN', 'GOAL', 'WASH', 'AB', 'BTY', 'HEARSE', 'PROTRUDE', 'TYPE', 'EASE', 'TOOTSIE', 'GOOSE', 'GOOD', 'AIDE', 'VOICE']\n",
    "except_vowel_words_2 = [] #holder list of words to remove. \n",
    "clean_vow_words_2 = []\n",
    "\n",
    "#first, let's call in all the words and find those that have xx_e and x_e patterns and get counts for those words and clean the words of these vowel phonemes\n",
    "\n",
    "\n",
    "for i, word in enumerate(clean_words_vow):  # iterate over the list of words, starting with word 0. For i starts count at 0 and enumerates through list\n",
    "    except_vowel_words = []\n",
    "#START HERE for TWO letter exceptions (i.e., AI_E as in AIDE and AISLE)\n",
    "    if re.search(r'AI[^AEIOU]E$', word):# basically will find anything with AI followed by a consonant followed by an E\n",
    "        #print(word) #\n",
    "        except_vowel_words.append(word)#put it into exception list to act on in a bit\n",
    "        for word in except_vowel_words:\n",
    "            #print(word) #these are the exception words for ea-e\n",
    "            for key, val in ai_dict.items(): #call in dictionary\n",
    "                #print(key)\n",
    "                while key in word: #while key is in word (to allow for multiple keys in a word (e.g., MEATHEAD)\n",
    "                    #print(key)\n",
    "                    prior_prob_vow[i].append(val[0])\n",
    "                    max_prob_vow[i].append(val[1]) \n",
    "                    min_prob_vow[i].append(val[2]) \n",
    "                    mid_prob_vow[i].append(val[3]) \n",
    "                    number_phonemes_vow[i].append(val[4]) \n",
    "                    word = word.replace(key, '', 1) #replace the key in the word with nothing (i.e., 'medal' becomes 'med')\n",
    "                    word = word[:-1] #remove the final e\n",
    "            clean_vow_words_2.append(word) #this is to keep list of remaining characters in words to return to larger list of words later\n",
    "        except_vowel_words_2.append(except_vowel_words)\n",
    "    if re.search(r'AU[^AEIOU]E$', word):# \n",
    "        #print(word) #\n",
    "        except_vowel_words.append(word)#put it into exception list to act on in a bit\n",
    "        for word in except_vowel_words:\n",
    "            #print(word) #these are the exception words for ea-e\n",
    "            for key, val in au_dict.items(): #call in dictionary\n",
    "                #print(key)\n",
    "                while key in word: #while key is in word\n",
    "                    #print(key)\n",
    "                    prior_prob_vow[i].append(val[0])\n",
    "                    max_prob_vow[i].append(val[1]) \n",
    "                    min_prob_vow[i].append(val[2]) \n",
    "                    mid_prob_vow[i].append(val[3]) \n",
    "                    number_phonemes_vow[i].append(val[4]) \n",
    "                    word = word.replace(key, '', 1) #replace the key in the word with nothing (i.e., 'medal' becomes 'med')\n",
    "                    word = word[:-1]\n",
    "            clean_vow_words_2.append(word) #this is to keep list of remaining characters in words to return to larger list of words later\n",
    "        except_vowel_words_2.append(except_vowel_words)\n",
    "    if re.search(r'AW[^AEIOU]E$', word):# \n",
    "        #print(word) #\n",
    "        except_vowel_words.append(word)#put it into exception list to act on in a bit\n",
    "        for word in except_vowel_words:\n",
    "            #print(word) #these are the exception words for ea-e\n",
    "            for key, val in aw_dict.items(): #call in dictionary\n",
    "                #print(key)\n",
    "                while key in word: #while key is in word\n",
    "                    #print(key)\n",
    "                    prior_prob_vow[i].append(val[0])\n",
    "                    max_prob_vow[i].append(val[1]) \n",
    "                    min_prob_vow[i].append(val[2]) \n",
    "                    mid_prob_vow[i].append(val[3]) \n",
    "                    number_phonemes_vow[i].append(val[4]) \n",
    "                    word = word.replace(key, '', 1) #replace the key in the word with nothing (i.e., 'medal' becomes 'med')\n",
    "                    word = word[:-1]\n",
    "            clean_vow_words_2.append(word) #this is to keep list of remaining characters in words to return to larger list of words later\n",
    "        except_vowel_words_2.append(except_vowel_words)   \n",
    "    if re.search(r'AY[^AEIOU]E$', word):# \n",
    "        #print(word) #this is GOOSE but not GOOD and TOOTSIE (works well)\n",
    "        except_vowel_words.append(word)#put it into exception list to act on in a bit\n",
    "        for word in except_vowel_words:\n",
    "            #print(word) #these are the exception words for ea-e\n",
    "            for key, val in ay_dict.items(): #call in dictionary\n",
    "                #print(key)\n",
    "                while key in word: #if key is in word\n",
    "                    #print(key)\n",
    "                    prior_prob_vow[i].append(val[0])\n",
    "                    max_prob_vow[i].append(val[1]) \n",
    "                    min_prob_vow[i].append(val[2]) \n",
    "                    mid_prob_vow[i].append(val[3]) \n",
    "                    number_phonemes_vow[i].append(val[4]) \n",
    "                    word = word.replace(key, '', 1) #replace the key in the word with nothing (i.e., 'medal' becomes 'med')\n",
    "                    word = word[:-1]\n",
    "            clean_vow_words_2.append(word) #this is to keep list of remaining characters in words to return to larger list of words later\n",
    "        except_vowel_words_2.append(except_vowel_words)   \n",
    "    if re.search(r'EA[^AEIOU]E$', word):# EA, .* means zero or more of any character, [^AEIOU] means non-vowels, E$ mean ends in E\n",
    "        #print(word) #this is just HEARSE and EASE\n",
    "        except_vowel_words.append(word)#put it into exception list to act on in a bit\n",
    "        for word in except_vowel_words:\n",
    "            #print(word) #these are the exception words for ea-e\n",
    "            for key, val in ea_dict.items(): #call in dictionary\n",
    "                #print(key)\n",
    "                while key in word: #if key is in word (i.e., does word EA, like EASE, but not EAT\n",
    "                    #print(key)\n",
    "                    prior_prob_vow[i].append(val[0])\n",
    "                    max_prob_vow[i].append(val[1]) \n",
    "                    min_prob_vow[i].append(val[2]) \n",
    "                    mid_prob_vow[i].append(val[3]) \n",
    "                    number_phonemes_vow[i].append(val[4]) \n",
    "                    word = word.replace(key, '', 1) #replace the key in the word with nothing (i.e., 'medal' becomes 'med')\n",
    "                    word = word[:-1]\n",
    "            clean_vow_words_2.append(word) #this is to keep list of remaining characters in words to return to larger list of words later\n",
    "        except_vowel_words_2.append(except_vowel_words)\n",
    "    if re.search(r'EE[^AEIOU]E$', word):# \n",
    "        #print(word) #\n",
    "        except_vowel_words.append(word)#put it into exception list to act on in a bit\n",
    "        for word in except_vowel_words:\n",
    "            #print(word) #these are the exception words for ea-e\n",
    "            for key, val in ee_dict.items(): #call in dictionary\n",
    "                #print(key)\n",
    "                while key in word: #if key is in word\n",
    "                    #print(key)\n",
    "                    prior_prob_vow[i].append(val[0])\n",
    "                    max_prob_vow[i].append(val[1]) \n",
    "                    min_prob_vow[i].append(val[2]) \n",
    "                    mid_prob_vow[i].append(val[3]) \n",
    "                    number_phonemes_vow[i].append(val[4]) \n",
    "                    word = word.replace(key, '', 1) #replace the key in the word with nothing (i.e., 'medal' becomes 'med')\n",
    "                    word = word[:-1]\n",
    "            clean_vow_words_2.append(word) #this is to keep list of remaining characters in words to return to larger list of words later\n",
    "        except_vowel_words_2.append(except_vowel_words) \n",
    "    if re.search(r'EI[^AEIOU]E$', word):# \n",
    "        #print(word) #\n",
    "        except_vowel_words.append(word)#put it into exception list to act on in a bit\n",
    "        for word in except_vowel_words:\n",
    "            #print(word) #these are the exception words for ea-e\n",
    "            for key, val in ei_dict.items(): #call in dictionary\n",
    "                #print(key)\n",
    "                while key in word: #if key is in word\n",
    "                    #print(key)\n",
    "                    prior_prob_vow[i].append(val[0])\n",
    "                    max_prob_vow[i].append(val[1]) \n",
    "                    min_prob_vow[i].append(val[2]) \n",
    "                    mid_prob_vow[i].append(val[3]) \n",
    "                    number_phonemes_vow[i].append(val[4]) \n",
    "                    word = word.replace(key, '', 1) #replace the key in the word with nothing (i.e., 'medal' becomes 'med')\n",
    "                    word = word[:-1]\n",
    "            clean_vow_words_2.append(word) #this is to keep list of remaining characters in words to return to larger list of words later\n",
    "        except_vowel_words_2.append(except_vowel_words)\n",
    "    if re.search(r'EU[^AEIOU]E$', word):# \n",
    "        #print(word) #\n",
    "        except_vowel_words.append(word)#put it into exception list to act on in a bit\n",
    "        for word in except_vowel_words:\n",
    "            #print(word) #these are the exception words for ea-e\n",
    "            for key, val in eu_dict.items(): #call in dictionary\n",
    "                #print(key)\n",
    "                while key in word: #if key is in word\n",
    "                    #print(key)\n",
    "                    prior_prob_vow[i].append(val[0])\n",
    "                    max_prob_vow[i].append(val[1]) \n",
    "                    min_prob_vow[i].append(val[2]) \n",
    "                    mid_prob_vow[i].append(val[3]) \n",
    "                    number_phonemes_vow[i].append(val[4]) \n",
    "                    word = word.replace(key, '', 1) #replace the key in the word with nothing (i.e., 'medal' becomes 'med')\n",
    "                    word = word[:-1]\n",
    "            clean_vow_words_2.append(word) #this is to keep list of remaining characters in words to return to larger list of words later\n",
    "        except_vowel_words_2.append(except_vowel_words)\n",
    "    if re.search(r'EW[^AEIOU]E$', word):# \n",
    "        #print(word) #\n",
    "        except_vowel_words.append(word)#put it into exception list to act on in a bit\n",
    "        for word in except_vowel_words:\n",
    "            #print(word) #these are the exception words for ea-e\n",
    "            for key, val in ew_dict.items(): #call in dictionary\n",
    "                #print(key)\n",
    "                while key in word: #if key is in word\n",
    "                    #print(key)\n",
    "                    prior_prob_vow[i].append(val[0])\n",
    "                    max_prob_vow[i].append(val[1]) \n",
    "                    min_prob_vow[i].append(val[2]) \n",
    "                    mid_prob_vow[i].append(val[3]) \n",
    "                    number_phonemes_vow[i].append(val[4]) \n",
    "                    word = word.replace(key, '', 1) #replace the key in the word with nothing (i.e., 'medal' becomes 'med')\n",
    "                    word = word[:-1]\n",
    "            clean_vow_words_2.append(word) #this is to keep list of remaining characters in words to return to larger list of words later\n",
    "        except_vowel_words_2.append(except_vowel_words)\n",
    "    if re.search(r'EY[^AEIOU]E$', word):# \n",
    "        #print(word) #\n",
    "        except_vowel_words.append(word)#put it into exception list to act on in a bit\n",
    "        for word in except_vowel_words:\n",
    "            #print(word) #these are the exception words for ea-e\n",
    "            for key, val in ey_dict.items(): #call in dictionary\n",
    "                #print(key)\n",
    "                while key in word: #if key is in word\n",
    "                    #print(key)\n",
    "                    prior_prob_vow[i].append(val[0])\n",
    "                    max_prob_vow[i].append(val[1]) \n",
    "                    min_prob_vow[i].append(val[2]) \n",
    "                    mid_prob_vow[i].append(val[3]) \n",
    "                    number_phonemes_vow[i].append(val[4]) \n",
    "                    word = word.replace(key, '', 1) #replace the key in the word with nothing (i.e., 'medal' becomes 'med')\n",
    "                    word = word[:-1]\n",
    "            clean_vow_words_2.append(word) #this is to keep list of remaining characters in words to return to larger list of words later\n",
    "        except_vowel_words_2.append(except_vowel_words)\n",
    "    if re.search(r'IA[^AEIOU]E$', word):# \n",
    "        #print(word) #\n",
    "        except_vowel_words.append(word)#put it into exception list to act on in a bit\n",
    "        for word in except_vowel_words:\n",
    "            #print(word) #these are the exception words for ea-e\n",
    "            for key, val in ia_dict.items(): #call in dictionary\n",
    "                #print(key)\n",
    "                while key in word: #if key is in word\n",
    "                    #print(key)\n",
    "                    prior_prob_vow[i].append(val[0])\n",
    "                    max_prob_vow[i].append(val[1]) \n",
    "                    min_prob_vow[i].append(val[2]) \n",
    "                    mid_prob_vow[i].append(val[3]) \n",
    "                    number_phonemes_vow[i].append(val[4]) \n",
    "                    word = word.replace(key, '', 1) #replace the key in the word with nothing (i.e., 'medal' becomes 'med')\n",
    "                    word = word[:-1]\n",
    "            clean_vow_words_2.append(word) #this is to keep list of remaining characters in words to return to larger list of words later\n",
    "        except_vowel_words_2.append(except_vowel_words)\n",
    "    if re.search(r'IE[^AEIOU]E$', word):# \n",
    "        #print(word) #\n",
    "        except_vowel_words.append(word)#put it into exception list to act on in a bit\n",
    "        for word in except_vowel_words:\n",
    "            #print(word) #these are the exception words for ea-e\n",
    "            for key, val in ie_dict.items(): #call in dictionary\n",
    "                #print(key)\n",
    "                while key in word: #if key is in word\n",
    "                    #print(key)\n",
    "                    prior_prob_vow[i].append(val[0])\n",
    "                    max_prob_vow[i].append(val[1]) \n",
    "                    min_prob_vow[i].append(val[2]) \n",
    "                    mid_prob_vow[i].append(val[3]) \n",
    "                    number_phonemes_vow[i].append(val[4]) \n",
    "                    word = word.replace(key, '', 1) #replace the key in the word with nothing (i.e., 'medal' becomes 'med')\n",
    "                    word = word[:-1]\n",
    "            clean_vow_words_2.append(word) #this is to keep list of remaining characters in words to return to larger list of words later\n",
    "        except_vowel_words_2.append(except_vowel_words)\n",
    "    if re.search(r'OA[^AEIOU]E$', word):# \n",
    "        #print(word) #\n",
    "        except_vowel_words.append(word)#put it into exception list to act on in a bit\n",
    "        for word in except_vowel_words:\n",
    "            #print(word) #these are the exception words for ea-e\n",
    "            for key, val in oa_dict.items(): #call in dictionary\n",
    "                #print(key)\n",
    "                while key in word: #if key is in word\n",
    "                    #print(key)\n",
    "                    prior_prob_vow[i].append(val[0])\n",
    "                    max_prob_vow[i].append(val[1]) \n",
    "                    min_prob_vow[i].append(val[2]) \n",
    "                    mid_prob_vow[i].append(val[3]) \n",
    "                    number_phonemes_vow[i].append(val[4]) \n",
    "                    word = word.replace(key, '', 1) #replace the key in the word with nothing (i.e., 'medal' becomes 'med')\n",
    "                    word = word[:-1]\n",
    "            clean_vow_words_2.append(word) #this is to keep list of remaining characters in words to return to larger list of words later\n",
    "        except_vowel_words_2.append(except_vowel_words)\n",
    "    if re.search(r'OI[^AEIOU]E$', word):# \n",
    "        #print(word) #\n",
    "        except_vowel_words.append(word)#put it into exception list to act on in a bit\n",
    "        for word in except_vowel_words:\n",
    "            #print(word) #these are the exception words for ea-e\n",
    "            for key, val in oi_dict.items(): #call in dictionary\n",
    "                #print(key)\n",
    "                while key in word: #if key is in word\n",
    "                    #print(key)\n",
    "                    prior_prob_vow[i].append(val[0])\n",
    "                    max_prob_vow[i].append(val[1]) \n",
    "                    min_prob_vow[i].append(val[2]) \n",
    "                    mid_prob_vow[i].append(val[3]) \n",
    "                    number_phonemes_vow[i].append(val[4]) \n",
    "                    word = word.replace(key, '', 1) #replace the key in the word with nothing (i.e., 'medal' becomes 'med')\n",
    "                    word = word[:-1]\n",
    "            clean_vow_words_2.append(word) #this is to keep list of remaining characters in words to return to larger list of words later\n",
    "        except_vowel_words_2.append(except_vowel_words)     \n",
    "    if re.search(r'OO[^AEIOU]E$', word):# \n",
    "        #print(word) #this is GOOSE but not GOOD and TOOTSIE (works well)\n",
    "        except_vowel_words.append(word)#put it into exception list to act on in a bit\n",
    "        for word in except_vowel_words:\n",
    "            #print(word) #these are the exception words for ea-e\n",
    "            for key, val in oo_dict.items(): #call in dictionary\n",
    "                #print(key)\n",
    "                while key in word: #if key is in word\n",
    "                    #print(key)\n",
    "                    prior_prob_vow[i].append(val[0])\n",
    "                    max_prob_vow[i].append(val[1]) \n",
    "                    min_prob_vow[i].append(val[2]) \n",
    "                    mid_prob_vow[i].append(val[3]) \n",
    "                    number_phonemes_vow[i].append(val[4]) \n",
    "                    word = word.replace(key, '', 1) #replace the key in the word with nothing (i.e., 'medal' becomes 'med')\n",
    "                    word = word[:-1]\n",
    "            clean_vow_words_2.append(word) #this is to keep list of remaining characters in words to return to larger list of words later\n",
    "        except_vowel_words_2.append(except_vowel_words)\n",
    "    if re.search(r'OU[^AEIOU]E$', word):# \n",
    "        #print(word) #\n",
    "        except_vowel_words.append(word)#put it into exception list to act on in a bit\n",
    "        for word in except_vowel_words:\n",
    "            #print(word) #these are the exception words for ea-e\n",
    "            for key, val in ou_dict.items(): #call in dictionary\n",
    "                #print(key)\n",
    "                while key in word: #if key is in word\n",
    "                    #print(key)\n",
    "                    prior_prob_vow[i].append(val[0])\n",
    "                    max_prob_vow[i].append(val[1]) \n",
    "                    min_prob_vow[i].append(val[2]) \n",
    "                    mid_prob_vow[i].append(val[3]) \n",
    "                    number_phonemes_vow[i].append(val[4]) \n",
    "                    word = word.replace(key, '', 1) #replace the key in the word with nothing (i.e., 'medal' becomes 'med')\n",
    "                    word = word[:-1]\n",
    "            clean_vow_words_2.append(word) #this is to keep list of remaining characters in words to return to larger list of words later\n",
    "        except_vowel_words_2.append(except_vowel_words)     \n",
    "    if re.search(r'OW[^AEIOU]E$', word):# \n",
    "        #print(word) #\n",
    "        except_vowel_words.append(word)#put it into exception list to act on in a bit\n",
    "        for word in except_vowel_words:\n",
    "            #print(word) #these are the exception words for ea-e\n",
    "            for key, val in ow_dict.items(): #call in dictionary\n",
    "                #print(key)\n",
    "                while key in word: #if key is in word\n",
    "                    #print(key)\n",
    "                    prior_prob_vow[i].append(val[0])\n",
    "                    max_prob_vow[i].append(val[1]) \n",
    "                    min_prob_vow[i].append(val[2]) \n",
    "                    mid_prob_vow[i].append(val[3]) \n",
    "                    number_phonemes_vow[i].append(val[4]) \n",
    "                    word = word.replace(key, '', 1) #replace the key in the word with nothing (i.e., 'medal' becomes 'med')\n",
    "                    word = word[:-1]\n",
    "            clean_vow_words_2.append(word) #this is to keep list of remaining characters in words to return to larger list of words later\n",
    "        except_vowel_words_2.append(except_vowel_words)     \n",
    "    if re.search(r'OY[^AEIOU]E$', word):# \n",
    "        #print(word) #\n",
    "        except_vowel_words.append(word)#put it into exception list to act on in a bit\n",
    "        for word in except_vowel_words:\n",
    "            #print(word) #these are the exception words for ea-e\n",
    "            for key, val in oy_dict.items(): #call in dictionary\n",
    "                #print(key)\n",
    "                while key in word: #if key is in word\n",
    "                    #print(key)\n",
    "                    prior_prob_vow[i].append(val[0])\n",
    "                    max_prob_vow[i].append(val[1]) \n",
    "                    min_prob_vow[i].append(val[2]) \n",
    "                    mid_prob_vow[i].append(val[3]) \n",
    "                    number_phonemes_vow[i].append(val[4]) \n",
    "                    word = word.replace(key, '', 1) #replace the key in the word with nothing (i.e., 'medal' becomes 'med')\n",
    "                    word = word[:-1]\n",
    "            clean_vow_words_2.append(word) #this is to keep list of remaining characters in words to return to larger list of words later\n",
    "        except_vowel_words_2.append(except_vowel_words)     \n",
    "    if re.search(r'UI[^AEIOU]E$', word):# \n",
    "        #print(word) #\n",
    "        except_vowel_words.append(word)#put it into exception list to act on in a bit\n",
    "        for word in except_vowel_words:\n",
    "            #print(word) #these are the exception words for ea-e\n",
    "            for key, val in ui_dict.items(): #call in dictionary\n",
    "                #print(key)\n",
    "                while key in word: #if key is in word\n",
    "                    #print(key)\n",
    "                    prior_prob_vow[i].append(val[0])\n",
    "                    max_prob_vow[i].append(val[1]) \n",
    "                    min_prob_vow[i].append(val[2]) \n",
    "                    mid_prob_vow[i].append(val[3]) \n",
    "                    number_phonemes_vow[i].append(val[4]) \n",
    "                    word = word.replace(key, '', 1) #replace the key in the word with nothing (i.e., 'medal' becomes 'med')\n",
    "                    word = word[:-1]\n",
    "            clean_vow_words_2.append(word) #this is to keep list of remaining characters in words to return to larger list of words later\n",
    "        except_vowel_words_2.append(except_vowel_words)   \n",
    "        \n",
    "        \n",
    "#NEXT, let's work on ONE letter exceptions (i.e., A_E as in ATE and SENATE)\n",
    "    if re.search(r'A[^AEIOU]E$', word):#AWE but not CASTLE. Screws up with equate for now...\n",
    "        #print(word) #\n",
    "        except_vowel_words.append(word)#put it into exception list to act on in a bit\n",
    "        for word in except_vowel_words:\n",
    "            #print(f' the word {word} matches A-E') #these are the exception words for a-e. \n",
    "            for key, val in a_dict.items(): #call in dictionary\n",
    "                #print(key)\n",
    "                while key in word: #if key is in word. This will count a word like DEVALUATE twice.... once as DEVALUATE, which will be changed to DEVALUTE, which will be counted a second time. Minor glitch in coding. Very rare.\n",
    "                    #print(f'the word {word} includes this key {key}')\n",
    "                    prior_prob_vow[i].append(val[0])\n",
    "                    max_prob_vow[i].append(val[1]) \n",
    "                    min_prob_vow[i].append(val[2]) \n",
    "                    mid_prob_vow[i].append(val[3]) \n",
    "                    number_phonemes_vow[i].append(val[4]) \n",
    "                    word = word.replace(key, '', 1) #replace the key in the word with nothing (i.e., 'medal' becomes 'med')\n",
    "                    word = word[:-1]\n",
    "            clean_vow_words_2.append(word) #this is to keep list of remaining characters in words to return to larger list of words later\n",
    "        except_vowel_words_2.append(except_vowel_words)     \n",
    "    if re.search(r'E[^AEIOU]E$', word):# \n",
    "        #print(word) #\n",
    "        except_vowel_words.append(word)#put it into exception list to act on in a bit\n",
    "        for word in except_vowel_words:\n",
    "            #print(word) #these are the exception words for ea-e\n",
    "            for key, val in e_dict.items(): #call in dictionary\n",
    "                #print(key)\n",
    "                while key in word: #if key is in word\n",
    "                    #print(key)\n",
    "                    prior_prob_vow[i].append(val[0])\n",
    "                    max_prob_vow[i].append(val[1]) \n",
    "                    min_prob_vow[i].append(val[2]) \n",
    "                    mid_prob_vow[i].append(val[3]) \n",
    "                    number_phonemes_vow[i].append(val[4]) \n",
    "                    word = word.replace(key, '', 1) #replace the key in the word with nothing (i.e., 'medal' becomes 'med')\n",
    "                    word = word[:-1]\n",
    "            clean_vow_words_2.append(word) #this is to keep list of remaining characters in words to return to larger list of words later\n",
    "        except_vowel_words_2.append(except_vowel_words)     \n",
    "    if re.search(r'I[^AEIOU]E$', word):# \n",
    "        #print(word) #\n",
    "        except_vowel_words.append(word)#put it into exception list to act on in a bit\n",
    "        for word in except_vowel_words:\n",
    "            #print(word) #these are the exception words for ea-e\n",
    "            for key, val in i_dict.items(): #call in dictionary\n",
    "                #print(key)\n",
    "                while key in word: #if key is in word\n",
    "                    #print(key)\n",
    "                    prior_prob_vow[i].append(val[0])\n",
    "                    max_prob_vow[i].append(val[1]) \n",
    "                    min_prob_vow[i].append(val[2]) \n",
    "                    mid_prob_vow[i].append(val[3]) \n",
    "                    number_phonemes_vow[i].append(val[4]) \n",
    "                    word = word.replace(key, '', 1) #replace the key in the word with nothing (i.e., 'medal' becomes 'med')\n",
    "                    word = word[:-1]\n",
    "            clean_vow_words_2.append(word) #this is to keep list of remaining characters in words to return to larger list of words later\n",
    "        except_vowel_words_2.append(except_vowel_words)     \n",
    "    if re.search(r'O[^AEIOU]E$', word):# the NORE in IGNORE but not the OTOTYPE in PROTOTYPE\n",
    "        #print(word) #\n",
    "        except_vowel_words.append(word)#put it into exception list to act on in a bit\n",
    "        for word in except_vowel_words:\n",
    "            #print(word) #these are the exception words for ea-e\n",
    "            for key, val in o_dict.items(): #call in dictionary\n",
    "                #print(key)\n",
    "                while key in word: #while key is in word\n",
    "                    #print(key)\n",
    "                    prior_prob_vow[i].append(val[0])\n",
    "                    max_prob_vow[i].append(val[1]) \n",
    "                    min_prob_vow[i].append(val[2]) \n",
    "                    mid_prob_vow[i].append(val[3]) \n",
    "                    number_phonemes_vow[i].append(val[4]) \n",
    "                    word = word.replace(key, '', 1) #replace the key in the word with nothing (i.e., 'medal' becomes 'med')\n",
    "                    word = word[:-1]\n",
    "            clean_vow_words_2.append(word) #this is to keep list of remaining characters in words to return to larger list of words later\n",
    "        except_vowel_words_2.append(except_vowel_words)     \n",
    "    if re.search(r'U[^AEIOU]E$', word):# \n",
    "        #print(word) #\n",
    "        except_vowel_words.append(word)#put it into exception list to act on in a bit\n",
    "        for word in except_vowel_words:\n",
    "            #print(word) #these are the exception words for ea-e\n",
    "            for key, val in u_dict.items(): #call in dictionary\n",
    "                #print(key)\n",
    "                while key in word: #if key is in word\n",
    "                    #print(key)\n",
    "                    prior_prob_vow[i].append(val[0])\n",
    "                    max_prob_vow[i].append(val[1]) \n",
    "                    min_prob_vow[i].append(val[2]) \n",
    "                    mid_prob_vow[i].append(val[3]) \n",
    "                    number_phonemes_vow[i].append(val[4]) \n",
    "                    word = word.replace(key, '', 1) #replace the key in the word with nothing (i.e., 'medal' becomes 'med')\n",
    "                    word = word[:-1]\n",
    "            clean_vow_words_2.append(word) #this is to keep list of remaining characters in words to return to larger list of words later\n",
    "        except_vowel_words_2.append(except_vowel_words)     \n",
    "    if re.search(r'Y[^AEIOU]E$', word):#The TYPE in PROTOTYPE \n",
    "        #print(word) #\n",
    "        except_vowel_words.append(word)#put it into exception list to act on in a bit\n",
    "        for word in except_vowel_words:\n",
    "            #print(word) #these are the exception words for ea-e\n",
    "            for key, val in y_dict.items(): #call in dictionary\n",
    "                #print(key)\n",
    "                while key in word: #if key is in word\n",
    "                    #print(key)\n",
    "                    prior_prob_vow[i].append(val[0])\n",
    "                    max_prob_vow[i].append(val[1]) \n",
    "                    min_prob_vow[i].append(val[2]) \n",
    "                    mid_prob_vow[i].append(val[3]) \n",
    "                    number_phonemes_vow[i].append(val[4]) \n",
    "                    word = word.replace(key, '', 1) #replace the key in the word with nothing (i.e., 'medal' becomes 'med')\n",
    "                    word = word[:-1]\n",
    "            clean_vow_words_2.append(word) #this is to keep list of remaining characters in words to return to larger list of words later\n",
    "        except_vowel_words_2.append(except_vowel_words)     \n",
    "    \n",
    "#clean_vow_words_3 = [] #these are the words stripped of final E\n",
    "        \n",
    "#for word in clean_vow_words_2:\n",
    "#    word = word[:-1] #this will replace all E's\n",
    "    #print(word)\n",
    "#    clean_vow_words_3.append(word)\n",
    "        \n",
    " \n",
    "#print(f'this is a list of words that had vowel exceptions {except_vowel_words_2}\\n')\n",
    "#print(f'this is a list of words after removing vowel exceptions including removing the final E {clean_vow_words_2}\\n')\n",
    "#print(f'this is a list of words cleaned of all exception vowel phonemes {clean_vow_words_3}\\n')\n",
    "#print(prior_prob_vow)\n",
    "#print(max_prob_vow)\n",
    "#print(min_prob_vow)\n",
    "#print(mid_prob_vow)\n",
    "#print(number_phonemes_vow)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118d9422-7c60-4f2f-895a-ef27367a564a",
   "metadata": {},
   "source": [
    "These were the counts after 3 and 4 character vowels\n",
    "\n",
    "['BOUGHT', 'MEN', 'EAT', 'TO', 'AWE', 'MIN', 'GOAL', 'WASH', 'AB', 'BEAUTY', 'HEARSE', 'RUDE', 'TYPE']\n",
    "[[0.0002], [], [], [], [], [], [], [], [], [0.0001], [], [], []]\n",
    "[[0.517], [], [], [], [], [], [], [], [], [0.545], [], [], []]\n",
    "[[0.068], [], [], [], [], [], [], [], [], [0.454], [], [], []]\n",
    "[[0.2925], [], [], [], [], [], [], [], [], [0.4995], [], [], []]\n",
    "[[4.0], [], [], [], [], [], [], [], [], [2.0], [], [], []]\n",
    "['BT', 'MEN', 'EAT', 'TO', 'AWE', 'MIN', 'GOAL', 'WASH', 'AB', 'BTY', 'HEARSE', 'RUDE', 'TYPE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa4b82c-477a-49f0-b49a-495130e1abc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clean_words_vow[:15]) #original words/character strings after 3-4 consonant vowels removed\n",
    "print(except_vowel_words_2[:15]) #words to remove from list above\n",
    "print(clean_vow_words_2[:15]) #character strings to replace them with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabbb065-658d-4373-9e62-6a02a31515ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(clean_words_vow))\n",
    "print(len(clean_vow_words_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0720e4b6-b7eb-4234-b661-806ce0e57df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now, we need a list for the next set of vowels\n",
    "#1. Make the words to remove a list\n",
    "#2. take the original words\n",
    "#3. remove the exception words that were processed\n",
    "#4. replace those words with their remaining parts after processing in the same order\n",
    "\n",
    "#change list of lists into a list\n",
    "vow_words_to_remove = []\n",
    "for sublist in except_vowel_words_2:\n",
    "    for word in sublist:\n",
    "        vow_words_to_remove.append(word)\n",
    "\n",
    "print(len(vow_words_to_remove))\n",
    "print(f'these are the words to remove and replace {vow_words_to_remove[:20]}')\n",
    "\n",
    "print(f'these are the remaining characters to replace the words above with {clean_vow_words_2[:20]}')\n",
    "\n",
    "print(len(clean_words_vow))\n",
    "print(f'these are the words cleaned of 3-4 character vowel phonemes {clean_words_vow[:20]}')\n",
    "\n",
    "\n",
    "# create a new list that will store the updated list of words where we replace the exception words with the leftovers\n",
    "clean_words_vow_4 = []\n",
    "\n",
    "# loop through the words in the original list\n",
    "for word in clean_words_vow:\n",
    "    #print(word)\n",
    "    # if the word was processed as an exception, replace it with the corresponding set of characters that remain after processing\n",
    "    if word in vow_words_to_remove:\n",
    "        #print(word)\n",
    "        #clean_words_vow_4.append(word) #there are 7668 words in this list, but there are 7917 words in vow_words_to_remove\n",
    "        clean_words_vow_4.append(clean_vow_words_2[vow_words_to_remove.index(word)])#index returns the position at the first occurrence of the specified value\n",
    "    # if the word is not in words_to_remove, add it to the processed_list_for_vowel_extraction list\n",
    "    else:\n",
    "        clean_words_vow_4.append(word)\n",
    "\n",
    "print(len(clean_words_vow_4))\n",
    "print(f'these are the words for the next section of counting (i.e., words removed of exception vowels {clean_words_vow_4[:20]}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print the final list for vowel probability extraction\n",
    "#print(f'this was the original list of words after 3-4 consonant vowels removed {clean_words_vow}\\n')\n",
    "#print(f'this is the list for next steps in vowel cleaning after exception vowels removed {clean_words_vow_4}') #Think this is right except for special, which should be spel, but is sp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b137ec-7cae-42b0-a997-8b70a3daf9fb",
   "metadata": {},
   "source": [
    "**The next steps are the following**\n",
    "\n",
    "1. Count and remove two character vowels\n",
    "2. Count and remove single character vowels\n",
    "\n",
    "This will give us vowel counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6afb32e-6e79-45f0-93b5-24422592cc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(clean_words_vow_4)\n",
    "clean_words_vow_5 = []\n",
    "\n",
    "for i, word in enumerate(clean_words_vow_4):  # iterate over the list of words, starting with word 0. For i starts count at 0 and enumerates through list\n",
    "    for key, val in berndt_2_vow_df_tran.items(): #next is 2 character vowel phonemes\n",
    "        while key in word: \n",
    "            #print(key) #the key\n",
    "            prior_prob_vow[i].append(val[0])\n",
    "            max_prob_vow[i].append(val[1]) \n",
    "            min_prob_vow[i].append(val[2]) \n",
    "            mid_prob_vow[i].append(val[3]) \n",
    "            number_phonemes_vow[i].append(val[4]) \n",
    "            word = word.replace(key, '', 1)\n",
    "    for key, val in berndt_1_vow_df_tran.items(): #next is 1 character vowel phonemes\n",
    "        while key in word:\n",
    "            #print(key) #the key\n",
    "            prior_prob_vow[i].append(val[0])\n",
    "            max_prob_vow[i].append(val[1]) \n",
    "            min_prob_vow[i].append(val[2]) \n",
    "            mid_prob_vow[i].append(val[3]) \n",
    "            number_phonemes_vow[i].append(val[4]) \n",
    "            word = word.replace(key, '', 1)\n",
    "    clean_words_vow_5.append(word) #this is a check to make sure the code is removing character phonemes\n",
    "\n",
    "#print(f'this was the original list of words {clean_words_vowels}\\n')\n",
    "#print(f'this is the list of words for final vowel cleaning with 2 and 1 character phonemes {clean_words_vow_4}\\n')\n",
    "#print(prior_prob_vow)\n",
    "#print(max_prob_vow)\n",
    "#print(min_prob_vow)\n",
    "#print(mid_prob_vow)\n",
    "#print(number_phonemes_vow)\n",
    "#print(f'this is what is left of the words with all the consonants counted {clean_words_vow_5}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44219838-7325-437f-b1e2-054293dcc3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'this is what is left of the words with all the consonants counted {clean_words_vow_5[:20]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593b3d78-02d0-494b-bcef-ff6757511c77",
   "metadata": {},
   "source": [
    "Now, need to get rid of any empty lists (unlikely with vowels, but I am sure there are exceptions.\n",
    "\n",
    "And, also average across lists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6378edc2-6a99-41ff-88b5-4a3e37962409",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in prior_prob_vow:\n",
    "     if len(item)==0:\n",
    "        #print(item)\n",
    "        item.append(0)\n",
    "\n",
    "for item in max_prob_vow:\n",
    "     if len(item)==0:\n",
    "        item.append(0)\n",
    "        \n",
    "for item in min_prob_vow:\n",
    "     if len(item)==0:\n",
    "        item.append(0)\n",
    "\n",
    "        \n",
    "for item in mid_prob_vow:\n",
    "     if len(item)==0:\n",
    "        item.append(0)\n",
    "\n",
    "        \n",
    "for item in number_phonemes_vow:\n",
    "     if len(item)==0:\n",
    "        item.append(0)\n",
    "\n",
    "\n",
    "prior_prob_vow_avg = [sum(sub_list) / len(sub_list) for sub_list in prior_prob_vow]\n",
    "max_prob_vow_avg = [sum(sub_list) / len(sub_list) for sub_list in max_prob_vow]\n",
    "min_prob_vow_avg = [sum(sub_list) / len(sub_list) for sub_list in min_prob_vow]\n",
    "mid_prob_vow_avg = [sum(sub_list) / len(sub_list) for sub_list in mid_prob_vow]\n",
    "number_phonemes_vow_avg = [sum(sub_list) / len(sub_list) for sub_list in number_phonemes_vow]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9376bba2-d53b-451a-ac03-d12c5eb9b91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prior_prob_vow_avg[:20])\n",
    "print(max_prob_vow_avg[:20])\n",
    "print(min_prob_vow_avg[:20])\n",
    "print(mid_prob_vow_avg[:20])\n",
    "print(number_phonemes_vow_avg[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02f478f-2f24-4bc2-810c-79890f1bf88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add to dataframe\n",
    "\n",
    "decoding_df['prior_prob_vowel'] = prior_prob_vow_avg #add to dataframe\n",
    "decoding_df['max_prob_vowel'] = max_prob_vow_avg #add to dataframe\n",
    "decoding_df['min_prob_vowel'] = min_prob_vow_avg #add to dataframe\n",
    "decoding_df['mid_prob_vowel'] = mid_prob_vow_avg #add to dataframe\n",
    "decoding_df['number_phonemes_vowel'] = number_phonemes_vow_avg #add to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc196ee9-fa53-4168-8f9b-b5eb8c401e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoding_df[34000:34100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765828de-5fb3-41c2-be7f-42a6f4e4d6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#decoding_df.to_csv(\"everything_including_vowel_prob.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f560942-8ad3-4475-9af6-de868bdcd64d",
   "metadata": {},
   "source": [
    "Now, probably need something that averages all the probability values across consonants and vowels.\n",
    "\n",
    "Can do the following\n",
    "\n",
    "1. Simple average (average of prior_prob_cons and prior_prob_vowel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebff7b7-1827-4208-88eb-ffb123051429",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoding_df['prior_prob_all'] = decoding_df[['prior_prob_cons', 'prior_prob_vowel']].mean(axis=1)\n",
    "decoding_df['max_prob_all'] = decoding_df[['max_prob_cons', 'max_prob_vowel']].mean(axis=1)\n",
    "decoding_df['mid_prob_all'] = decoding_df[['mid_prob_cons', 'mid_prob_vowel']].mean(axis=1)\n",
    "decoding_df['min_prob_all'] = decoding_df[['min_prob_cons', 'min_prob_vowel']].mean(axis=1)\n",
    "decoding_df['number_phonemes_all'] = decoding_df[['number_phonemes_cons', 'number_phonemes_vowel']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88577060-7e3e-437c-a99f-d7381dd73734",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoding_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90baa374-c118-4837-bf1f-f02f1e2130b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoding_df.to_csv(\"everything_including_vowel_prob.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
